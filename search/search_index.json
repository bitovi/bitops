{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<ul> <li>Keeps the working environment clean</li> <li>Organizes your deployment configuration</li> <li>Faster developer onboarding</li> <li>Integrates with your favorite tools</li> <li>Saves weeks of engineering efforts</li> <li>Encourages GitOps best practices</li> <li>Open source and free</li> </ul> BitOps centralizes, organizes, and deploys your Infrastructure-as-Code Show me how <p>BitOps is an automated orchestrator for deployment tools using GitOps. </p> <p>It leverages a way to describe the infrastructure for many environments and IaC tools called an Operations Repository.</p> Features Configurable <p>Tell BitOps what deployment tools and parameters it needs to deploy your application through environment variables or yaml-based configuration.</p> Event Hooks <p>If BitOps doesn't have built-in support for your use case, BitOps can execute arbitrary bash scripts at different points in its lifecycle.</p> Customizable <p>Our newest feature Plugins offer a layer of plug-and-play specialization with the BitOps core. Use one of our officially supported plugins or make your own!</p> Runs Anywhere <p>By bundling all logic in BitOps, you can have the same experience regardless of which pipeline service runs your CI. You can even run BitOps locally!</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#support-contributing","title":"Support / Contributing","text":"<p>We welcome any contributions or suggestions from the community with open arms. Take a look at our Contributing guide.</p> <p>Come hangout with us in Discord! <code>#bitops</code> channel!</p>"},{"location":"about/#release-history","title":"Release History","text":"<p>See Releases.</p>"},{"location":"about/#license","title":"License","text":"<p>MIT License.</p>"},{"location":"ci-pipeline/","title":"Ci pipeline","text":"<p>The CI pipeline that creates new BitOps images is made up of 3 distinct actions; </p> <ol> <li> <p>A BitOps base image is created which contains python3, jq, git as well as a few other utilities. </p> </li> <li> <p>The final step of the base BitOps image build performs a minor bump to the bitops-tag file</p> </li> <li> <p>A CI pipeline is watching the <code>bitops-tag</code> file, if there is an update it triggers a github action that creates a new set of prebuilt images.</p> </li> </ol> <p>The logic is that a base image recreation is triggered if any change happens to the BitOps source code which subsequently triggers the recreation of all prebuilt images. </p> <p>This effectively softlinks the CI pipelines as though they are able to run independent of the other, they are intended to be used in succession.</p>"},{"location":"ci-pipeline/#break-down-of-ci-triggers","title":"Break down of CI triggers","text":""},{"location":"ci-pipeline/#base","title":"Base","text":""},{"location":"ci-pipeline/#push","title":"Push","text":"<pre><code>    # ~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- #\n    #                   PUSH                   #\n    # ~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- #  \n    - name: Publish Docker Image (Push)\n      env:\n        REGISTRY_URL: \"bitovi/bitops\"\n        DEFAULT_BRANCH: \"plugins\"\n        DOCKER_USER: ${{ secrets.DOCKER_USER}}\n        DOCKER_PASS: ${{ secrets.DOCKER_PASS}}\n        IMAGE_TAG: ${{ env.BASE_TAG}}\n      run: |\n        echo \"running scripts/ci/publish.sh\"\n        ./scripts/ci/publish.sh\n      if: github.event_name == 'push'\n</code></pre> <p>The push trigger will perform a basic rebuild of the base image but it will not bump the bitops-version, therefor this trigger does not trigger the subsequent prebuilt image CI. </p>"},{"location":"ci-pipeline/#workflow-dispatch","title":"Workflow dispatch","text":"<pre><code>    # ~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- #\n    #           Workflow dispatch              #\n    # ~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- # \n    - name: Publish Docker Image (Workflow dispatch)\n      env:\n        REGISTRY_URL: \"bitovi/bitops\"\n        DEFAULT_BRANCH: \"plugins\"\n        DOCKER_USER: ${{ secrets.DOCKER_USER}}\n        DOCKER_PASS: ${{ secrets.DOCKER_PASS}}\n        IMAGE_TAG: ${{ github.event.inputs.bitops_base_tag}}\n      run: |\n        echo \"running scripts/ci/publish.sh\"\n        ./scripts/ci/publish.sh\n        echo \"IMAGE_TAG=${{ github.event.inputs.bitops_base_tag}}\" &gt;&gt; $GITHUB_ENV\n        echo \"IMAGE_BUMP=${{ github.event.release.bump_base_tag }}\" &gt;&gt; $GITHUB_ENV\n      if: github.event_name == 'workflow_dispatch'\n</code></pre> <p>The workflow dispatch trigger will create a custom BitOps image name, and provides the boolean option to bump the prebuilt-config/bitops-tag.yaml<code>:tags.bitops-tag</code></p>"},{"location":"ci-pipeline/#release","title":"Release","text":"<pre><code>    # ~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- #\n    #                Release                   #\n    # ~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~-~- #\n    - name: Publish Docker Image (Release)\n      env:\n        REGISTRY_URL: \"bitovi/bitops\"\n        DEFAULT_BRANCH: \"plugins\"\n        DOCKER_USER: ${{ secrets.DOCKER_USER}}\n        DOCKER_PASS: ${{ secrets.DOCKER_PASS}}\n        IMAGE_TAG: ${{ github.event.release.tag_name }}-base\n      run: |\n        echo \"running scripts/ci/publish.sh\"\n        ./scripts/ci/publish.sh\n        echo \"IMAGE_TAG=${{ github.event.release.tag_name }}-base\" &gt;&gt; $GITHUB_ENV\n        echo \"IMAGE_BUMP=true\" &gt;&gt; $GITHUB_ENV\n      if: github.event_name == 'release'\n</code></pre> <p>Creates a new base image based on the tag of the release and bumps the prebuilt-config/bitops-tag.yaml<code>:tags.bitops-tag</code></p>"},{"location":"ci-pipeline/#prebuilt","title":"Prebuilt","text":""},{"location":"ci-pipeline/#push_1","title":"Push","text":"<p>The CI pipeline watches the prebuilt-config/bitops-tag.yaml file and if an update occurs to the <code>tags.bitops_base</code> tag then it rebuilds using the new version.</p>"},{"location":"ci-pipeline/#workflow-dispatch_1","title":"Workflow dispatch","text":"<p>The user who triggers the workflow dispatch must specify a image tag for the plugins image name. For example if <code>2.0.0</code> was entered as the <code>image_tag</code> then a resulting image would be; <code>2.0.0-&lt;tool&gt;</code>. The value of tool is determined from the CI matrix within the build-and-publish-prebuilt.yaml</p>"},{"location":"configuration-base/","title":"Base Configuration","text":"<p>Each deployment tool is traditionally controlled with a set of CLI arguments. Instead of defining arguments within your pipeline configuration, they can instead either be defined with environment variables or in a <code>bitops.config.yaml</code> file. While the core schema for a <code>bitops.config.yaml</code> file is common between tools, the specific properties and environment variable equivalents vary from tool to tool.</p> <p>For more information on tool configuration, see plugins.</p>"},{"location":"configuration-base/#base-schema","title":"Base Schema","text":"<p>All <code>bitops.config.yaml</code> files share the following structure <pre><code>$tool\n  cli: {}\n  options: {}\n</code></pre></p> <ul> <li><code>$tool</code> - identifies the deployment tool</li> <li><code>cli</code> - object that contains CLI arguments</li> <li><code>options</code> - an object that offers additional control over how a tool executes</li> </ul>"},{"location":"configuration-base/#environment-variable-defaulting","title":"Environment Variable Defaulting","text":"<p>Plugin environment variables are automatically mapped to the <code>bitops.config.yaml</code> keys. This means that you can use the same environment variable names as in the plugin config. For example, if you want to override the <code>ansible.cli.skip-tags</code> value, you can use the <code>BITOPS_ANSIBLE_SKIP_TAGS</code> environment variable. In this case, <code>BITOPS</code> is the prefix, <code>ANSIBLE</code> is the plugin name, and <code>SKIP_TAGS</code> is the key name (note hypens are replaced with underscores).</p> <p>The precedence order is: <code>ENV</code> vars &gt; <code>bitops.config.yaml</code> values &gt; <code>bitops.config.schema.yaml</code> defaults. This way, ENV variables specified by user are taking highest precedence over config values and defaults. We recommend using them dynamically in CI/CD pipelines to control the deployment based on condition (PR run, branch, etc) or manually passing to the the BitOps docker container.</p>"},{"location":"configuration-base/#opsrepo-configuration-override","title":"OpsRepo configuration override","text":"<p>BitOps configuration is overridable by OpsRepo level <code>bitops.config.yaml</code> configuration files. The OpsRepo BitOps configuration file is expected to be found in the <code>OpsRepo/ENVIRONMENT</code> directory.</p> <p>These configuration files use the same schema as the <code>bitops/bitops.schema.yaml</code>, all values in the bitops schema can be configured from the OpsRepo level <code>bitops.config.yaml</code>. The bitops/bitops.config.yaml file sets the default run pattern for bitops and can be used as an example to write OpsRepo bitops configuration.</p> <p>Example OpsRepo config file path <pre><code>OpsRepo/\n|___ Dev/\n|       bitops.config.yaml\n|_______terraform/\n|_______ansible/\n</code></pre></p> <p>Example BitOps configuration override <pre><code>bitops:\n  deployments:\n    deploy-part-1:\n      plugin: terraform\n    deploy-part-2:\n      plugin: terraform\n    deploy-part-3:\n      plugin: ansible\n</code></pre></p>"},{"location":"configuration-base/#arbitrary-environment-variables","title":"Arbitrary Environment Variables","text":"<p>During the docker run command, you can specify an ENV var and it will be accessible during all processing stages of BitOps. This is useful for passing in secrets or other custom values used in the workflows.</p>"},{"location":"configuration-base/#common-configuration","title":"Common Configuration","text":"<p>There are some global configuration options that are shared among all tools and cloud providers during a BitOps run. These are set via environment variables</p> Property Environment Variable Description Default Required environment BITOPS_ENVIRONMENT Each BitOps run is done against a single environment. This property tells BitOps which environment to run. For more information on environments, see Operations Repo Structure. Yes kubeconfig_base64 KUBECONFIG_BASE64 Base64 encoded <code>kubeconfig</code> file. Allows deployment tools to interact with a Kubernetes cluster. <code>null</code> No"},{"location":"configuration-base/#cloud-providers","title":"Cloud Providers","text":"<ul> <li>AWS</li> </ul>"},{"location":"configuration-base/#tool-configuration","title":"Tool Configuration","text":"<ul> <li>Ansible</li> <li>Helm</li> <li>Terraform</li> <li>Cloudformation</li> </ul>"},{"location":"contributing/","title":"How to Contribute","text":"<p>Issues and suggestions can be logged on GitHub</p>"},{"location":"contributing/#want-to-fix-it-yourself","title":"Want to fix it yourself","text":"<p>We'd love to accept your patches and contributions to this project. There are just a few small guidelines you need to follow.</p> <p>When you are ready to get started developing, see our development guide for how to get started!</p>"},{"location":"contributing/#bitops-community-meetings","title":"BitOps Community Meetings","text":"<p>Join bi-weekly community meetups organized by the BitOps core team and contributors. Every <code>2nd Wednesday</code> at <code>12:00 PM US East</code> we\u2019re gathering for <code>1 hour</code> to discuss the ongoing BitOps work, issues, plans, and ideas.</p> <p>General Agenda:</p> <ul> <li>Roadmap and Milestones</li> <li>Issues and Discussions</li> <li>Features and Proposals</li> <li>Use cases and user Adoption</li> </ul> <p>See BitOps Community Meetings for more info how to join.</p> <p>We would like to invite everyone interested to join us!</p>"},{"location":"contributing/#developer-certificate-of-origin","title":"Developer Certificate of Origin","text":"<p>To contribute to this project, you must agree to the Developer Certificate of Origin (DCO) for each commit you make. The DCO is a simple statement that you, as a contributor, have the legal right to make the contribution.</p> <p>See the DCO file for the full text of what you must agree to.</p> <p>To signify that you agree to the DCO for a commit, you add a line to the git commit message:</p> <pre><code>Signed-off-by: Jane Smith &lt;jane.smith@example.com&gt;\n</code></pre> <p>In most cases, you can add this signoff to your commit automatically with the <code>-s</code> flag to <code>git commit</code>. You must use your real name and a reachable email address (sorry, no pseudonyms or anonymous contributions).</p>"},{"location":"contributing/#code-reviews","title":"Code reviews","text":"<p>All submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose.</p>"},{"location":"custom-image/","title":"Custom Images","text":"<p>In this section we will learn how we can create a custom BitOps image with plugins and additional utilities.</p>"},{"location":"custom-image/#create-a-custom-bitops-repo","title":"Create a custom bitops repo","text":"<p>First thing is first, if you haven't already create a repo for your custom bitops image</p>"},{"location":"custom-image/#modify-the-bitopsconfigyaml","title":"Modify the bitops.config.yaml","text":"<p>Using your preferred editor, create a file in the root level of the project and call it; <code>bitops.config.yaml</code></p> <p>This file is used to configure the BitOps image.</p> <p>Example bitops.config.yaml</p>"},{"location":"custom-image/#bitopsconfigyaml","title":"bitops.config.yaml","text":""},{"location":"custom-image/#bitops-official-image","title":"BitOps \"official\" image","text":"<p>Below is an example of how the \"official latest\" image of BitOps is configured. </p> <p>As you can see there are two sections we need to be aware of; Plugins and Deployments. </p> <p></p>"},{"location":"custom-image/#plugins","title":"plugins","text":"<p>Defines a plugin and the source for that plugin. </p> <p></p>"},{"location":"custom-image/#deployment","title":"Deployment","text":"<p>Defines alias', the sequence of executions for those alias' and the alias' related plugin.</p>"},{"location":"custom-image/#official-image","title":"official image","text":"<pre><code>  plugins:    \n    aws:\n      source: https://github.com/bitops-plugins/aws\n    terraform:\n      source: https://github.com/bitops-plugins/terraform\n    cloudformation:\n      source: https://github.com/bitops-plugins/cloudformation\n    helm:\n      source: https://github.com/bitops-plugins/helm\n    kubectl:\n      source: https://github.com/bitops-plugins/kubectl\n    ansible:\n      source: https://github.com/bitops-plugins/ansible\n  deployments:\n    cloudformation:\n      plugin: cloudformation\n    terraform:\n      plugin: terraform\n    helm:\n      plugin: helm\n    ansible:\n      plugin: ansible\n</code></pre>"},{"location":"custom-image/#custom-image-example","title":"Custom image example","text":"<p>In the example below we define 2 plugins that BitOps will install, <code>plugin-name-1</code> and <code>plugin-name-2</code>. </p> <p>In the deployment section we specify 3 alias' that we will act on in our ops_repo. We also specify which plugin we'd like to make that action. </p> <pre><code>plugins:\n    plugin-name-1:\n        source: url-to-plugin-1\n    plugin-name-2:\n        source: url-to-plugin-2\ndeployments:\n    alias-name-1:\n        plugin: plugin-name-1\n    alias-name-2:\n        plugin: plugin-name-2\n    alias-name-3:\n        plugin: plugin-name-1\n</code></pre> <p>So continuing with our example, the ops_repo would look like;  <pre><code>OPS_REPO/\n    ENV/\n        alias-name-1/\n            ... \n        alias-name-2/\n            ...\n        alias-name-3/\n            ...\n</code></pre></p> <pre><code>OPS_REPO/\n    ENV/\n        alias-name-1/ # &lt;-- plugin-name-1 would be actioned on this folder\n            ... \n        alias-name-2/ # &lt;-- plugin-name-2 would be actioned on this folder\n            ...\n        alias-name-3/ # &lt;-- plugin-name-1 would be actioned on this folder\n            ...\n</code></pre>"},{"location":"custom-image/#build-and-run-the-image","title":"Build and run the image","text":"<p>The final steps are to build and run the image. You can find example commands to accomplish this in the local development section</p>"},{"location":"default-environment/","title":"Default Environment","text":"<p>There are instances where configuration or variable files should be shared between environments. Instead of duplicating common files across different environments, the <code>_default</code> environment can be used instead.</p> <p>Suppose we are working with an operations repo that is exlusviely terraform. We have a <code>production</code> and <code>test</code> environment that have the same HCL, but different input variables between the two. This is a great candidate for the <code>_default</code> environment. The common configuration can be put in the <code>_default/</code> environment directory instead of in both <code>production/</code> and <code>test/</code> environments:</p> <p><pre><code>\u251c\u2500\u2500 _default\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u251c\u2500\u2500 production\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 bitops.config.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 production.auto.tfvars\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 terraform\n        \u2514\u2500\u2500 bitops.config.yaml\n        \u2514\u2500\u2500 test.auto.tfvars\n</code></pre> When <code>$BITOPS_ENVIRONMENT</code> is set to <code>production</code>, <code>_default/</code> will be merged into <code>production/</code> at runtime to produce a directory structure that looks this way: <pre><code>\u251c\u2500\u2500 _default\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u251c\u2500\u2500 production\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 bitops.config.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 production.auto.tfvars\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 terraform\n        \u2514\u2500\u2500 bitops.config.yaml\n        \u2514\u2500\u2500 test.auto.tfvars\n</code></pre></p> <p>Things get more complex when files that exist in both the <code>_default</code> and <code>active</code> environment share the same name. This is why we have file mergers.</p>"},{"location":"default-environment/#file-mergers-todo","title":"File Mergers TODO","text":"<p>Different files have different behvaviors based on the file extension + the deployment tool. Some files can be merged together, others can't. This behavior is defined below.</p>"},{"location":"default-environment/#tf-hcl-handling","title":"<code>.tf</code> (HCL) Handling","text":"<p>Files that only exist in the <code>_default</code> environment will be copied over.</p> <p><code>.tf</code> files from the <code>_default</code> environment that share its name and path with a file in the active environment will both be in the resulting directory with the active environment name having a suffix added to it.</p>"},{"location":"default-environment/#example","title":"Example","text":"<p>Before default merge: <pre><code>\u251c\u2500\u2500 _default\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 terraform\n        \u2514\u2500\u2500 bitops.config.yaml\n        \u2514\u2500\u2500 main.tf\n</code></pre> After default merge: <pre><code>\u251c\u2500\u2500 _default\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 main.tf\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 terraform\n        \u2514\u2500\u2500 bitops.config.yaml\n        \u2514\u2500\u2500 main.tf.test.tf\n        \u2514\u2500\u2500 main.tf # This comes from default/terraform/main.tf\n</code></pre> This is accomplished with an <code>rsync</code> operation <pre><code>DEFAULT_DIR=_default\nENV_DIR=test\nrsync -ab --suffix \".${ENV_DIR}.tf\" --include=\"*/\" --include=\"*.tf\" --exclude=\"*\"  $DEFAULT_DIR/ $ENV_DIR/\n</code></pre></p>"},{"location":"default-environment/#sh-handling","title":".sh Handling","text":"<p>Files that only exist in the <code>_default</code> environment will be copied over.</p> <p><code>.sh</code> files from the <code>_default</code> environment that share its name and path with a file in the active environment will not be copied over.</p>"},{"location":"default-environment/#example_1","title":"Example","text":"<p>Before default merge <pre><code>\u251c\u2500\u2500 _default\n\u2502   \u2514\u2500\u2500 terraform\n\u2502       \u251c\u2500\u2500 bitops.after-deploy.d\n\u2502       \u2502\u00a0\u00a0 \u2514\u2500\u2500 default-after-script.sh\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 terraform\n        \u2514\u2500\u2500 bitops.config.yaml\n        \u2514\u2500\u2500 main.tf\n</code></pre> After default merge <pre><code>\u251c\u2500\u2500 _default\n\u2502   \u2514\u2500\u2500 terraform\n\u2502       \u251c\u2500\u2500 bitops.after-deploy.d\n\u2502       \u2502\u00a0\u00a0 \u2514\u2500\u2500 default-after-script.sh\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 terraform\n        \u251c\u2500\u2500 bitops.after-deploy.d\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 default-after-script.sh # Copied from default/terraform/bitops.after-deploy.d/default-after-script.sh\n        \u2514\u2500\u2500 main.tf\n</code></pre></p>"},{"location":"default-environment/#general-yamlyml","title":"General .yaml/.yml","text":"<p>Files that only exist in the <code>_default</code> environment will be copied over.</p> <p>Files from the <code>_default</code> environment that share its name and path will be merged.</p>"},{"location":"default-environment/#valuesyaml-helm","title":"values.yaml (Helm)","text":"<p>Helm has built in support for merging multiple <code>values.yaml</code> files. BitOps will look for files in the following locations and pass them in to helm with the <code>-f</code> in the same order they are found:</p> <ol> <li>Active environment's <code>values.yaml</code></li> <li>Default environment's <code>values.yaml</code></li> <li>Active environment's <code>values-versions.yaml</code></li> <li>Default environment's <code>values-versions.yaml</code></li> <li>Any yaml in active environment's <code>$chart/values-files/</code> directory</li> <li>Any yaml in default environment's <code>$chart/values-files/</code> directory</li> </ol>"},{"location":"default-environment/#example_2","title":"Example","text":"<p>The following operations repo structure <pre><code>\u251c\u2500\u2500 _default\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 helm\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 my-first-chart\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 values-files\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 my-first-chart-default-values.yaml\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 values-versions.yaml\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 values.yaml\n\u2514\u2500\u2500 test\n    \u2514\u2500\u2500 helm\n        \u251c\u2500\u2500 bitops.config.yaml\n        \u2514\u2500\u2500 my-first-chart\n            \u251c\u2500\u2500 values-files\n            \u2502\u00a0\u00a0 \u2514\u2500\u2500 my-first-chart-values.yaml\n            \u251c\u2500\u2500 values-versions.yaml\n            \u2514\u2500\u2500 values.yaml\n</code></pre> Will produce the following <code>helm install</code> command <pre><code>helm install \\\n$HELM_RELEASE_NAME \\ \nmy-first-chart \\\n-f test/helm/my-first-chart/values.yaml \\\n-f default/helm/my-first-chart/values.yaml \\\n-f test/helm/my-first-chart/values-versions.yaml \\\n-f default/helm/my-first-chart/values-versions.yaml \\\n-f test/helm/my-first-chart/values-files/my-first-chart-values.yaml \\\n-f default/helm/my-first-chart/values-files/my-first-chart-default-values.yaml\n</code></pre></p>"},{"location":"development-local/","title":"Getting Started","text":"<p>To get started, you\u2019ll need - Docker locally - The BitOps repo on your local machine - An Operations Repository on your local machine - [optional] A BitOps plugin on your local machine</p>"},{"location":"development-local/#general-idea","title":"General Idea","text":"<p>To test and work on BitOps locally, a common approach is to pull the latest (or most recent versioned) BitOps image and then mount your local repos to the relevant locations when you run the BitOps container.</p> <p>Additionally, you might want to make use of the \u201cdry-run\u201d functionality (dry-run: true for Helm, plan for Terraform, for example) for your deployments so that you are not modifying external resources during your testing.</p> <p>It\u2019s also useful to modify the BitOps or Plugin code to output extra debugging information or to bypass the actual deployment once you\u2019ve pinpointed where the issue might be.</p> <p>Be sure to remove all debugging code/modifications prior to merging!</p>"},{"location":"development-local/#create-your-branches","title":"Create your branches","text":"<p>Check out each of your repos (BitOps, your Operations Repo, and your BitOps Plugin repo).</p> <p>For each repo, create a branch locally to capture your changes.</p>"},{"location":"development-local/#pull-latest-bitops","title":"Pull latest BitOps","text":"<p>In this example, we\u2019ll pull BitOps version 2.1.0 since, at the time of this writing, 2.1.0 is the most recent version, so that\u2019s where we want to start.</p> <pre><code>docker pull bitovi/bitops:2.1.0\n</code></pre>"},{"location":"development-local/#craft-your-deploy-script","title":"Craft your deploy script","text":"<p>Build a Docker run command to mount all the repos and kick off a BitOps deployment locally:</p> <pre><code>docker run --rm --name bitops \\\n-e AWS_ACCESS_KEY_ID=\"${AWS_ACCESS_KEY_ID}\" \\\n-e AWS_SECRET_ACCESS_KEY=\"${AWS_SECRET_ACCESS_KEY}\" \\\n-e AWS_SESSION_TOKEN=\"${AWS_SESSION_TOKEN}\" \\\n-e AWS_DEFAULT_REGION=\"${AWS_DEFAULT_REGION}\" \\\n-e BITOPS_ENVIRONMENT=\"prod\" \\\n-e BITOPS_ENVIRONMENT_HELM_SUBDIRECTORY=\"aws-auth\" \\\n-e TERRAFORM_SKIP_DEPLOY=\"true\" \\\n-e HELM_SKIP_DEPLOY=\"\" \\\n-e DEFAULT_FOLDER_NAME=\"_default\" \\\n-v /path/to/operations-repo:/opt/bitops_deployment \\\n-v /path/to/bitops:/opt/bitops \\\n-v /path/to/bitops/prebuilt-config/omnibus/bitops.config.yaml:/opt/bitops/bitops.config.yaml \\\n-v /opt/bitops/scripts/plugins/aws \\\n-v /opt/bitops/scripts/plugins/terraform \\\n-v /opt/bitops/scripts/plugins/cloudformation \\\n-v /opt/bitops/scripts/plugins/kubectl \\\n-v /opt/bitops/scripts/plugins/ansible \\\n-v /path/to/bitops-plugins/helm:/opt/bitops/scripts/plugins/helm \\\nbitovi/bitops:2.1.0\n</code></pre>"},{"location":"development-local/#breaking-down-the-deploy-script","title":"Breaking down the deploy script","text":"Command Description <code>docker run --rm --name bitops \\</code> Run the docker container, name it bitops, and remove the container when it exits -e AWS_ACCESS_KEY_ID=\"\\${AWS_ACCESS_KEY_ID}\" \\  -e AWS_SECRET_ACCESS_KEY=\"\\${AWS_SECRET_ACCESS_KEY}\" \\  -e AWS_SESSION_TOKEN=\"\\${AWS_SESSION_TOKEN}\" \\ AWS credentials/config <code>-e BITOPS_ENVIRONMENT=\"prod\" \\</code> Set the BitOps environment to deploy (in this example, prod) <code>-e BITOPS_ENVIRONMENT_HELM_SUBDIRECTORY=\"aws-auth\" \\</code> Set the specific Helm chart to deploy (in this example, aws-auth). -e TERRAFORM_SKIP_DEPLOY=\"true\" \\  -e HELM_SKIP_DEPLOY=\"\" \\ Skip the Terraform deployment but not the Helm deployment (you could also omit HELM_SKIP_DEPLOY). <code>-e DEFAULT_FOLDER_NAME=\"_default\" \\</code> Define the directory to pull defaults from.  Default should be _default, so this could be omitted if your default environment is _default. -v /path/to/operations-repo:/opt/bitops_deployment \\ Mount your local operations repo to the location BitOps expects it to be. -v /path/to/bitops:/opt/bitops \\ Mount your local BitOps repo to the location BitOps expects it to be (i.e. /opt/bitops).  This way, you can make changes to the BitOps code locally, and changes will be reflected when you run the docker run command. <code>-v /path/to/bitops/prebuilt-config/omnibus/bitops.config.yaml:/opt/bitops/bitops.config.yaml \\</code> Specify a specific bitops.config.yaml from the prebuilt-config so that BitOps knows how to handle deployments. BitOps looks for a bitops.config.yaml in the root directory to determine how (i.e. in which order) to execute deployments.  The bitops.config.yaml in the root directory has empty deployments, so we need content there.  This line mounts one of the prebuilt-config\u2019s bitops.config.yaml (namely, the omnibus bitops.config.yaml) to the root of the repo. -v /opt/bitops/scripts/plugins/aws \\  -v /opt/bitops/scripts/plugins/terraform \\  -v /opt/bitops/scripts/plugins/cloudformation \\  -v /opt/bitops/scripts/plugins/kubectl \\  -v /opt/bitops/scripts/plugins/ansible \\ These lines essentially tell Docker to use the specified directories from within the container rather than from the host.  Since we are mounting the entire BitOps directory to a container that should have plugins but we\u2019re not running a build to perform a plugin install, we need to use the plugins that were installed into the container as they do not exist on the host. <code>-v /path/to/bitops-plugins/helm:/opt/bitops/scripts/plugins/helm \\</code> This mounts your local plugin repo (in this example, helm) to the appropriate location within the container. <code>bitovi/bitops:2.1.0</code> Use a specific BitOps version as the basis for your work.  You\u2019ll want to ensure you\u2019re working against the most recent release (either the most recent versioned image or latest)"},{"location":"development-local/#linting","title":"Linting","text":"<p>Before submitting a PR it is recommended that you locally run a linter to ensure code standards are met. </p> <pre><code>tox -e black\ntox -e pylint\n</code></pre>"},{"location":"development-local/#python-debugging-with-vscode","title":"Python Debugging with VSCode","text":"<p>If you are using VSCode, you can rely on the Python and Docker extensions to debug your code.</p> <p>This VSCode config (in <code>.vscode/</code>) allows running the Python debugging in a BitOps container, sharing the directories with the local python source code and plugin code.</p>"},{"location":"development-local/#instructions","title":"Instructions","text":"<ul> <li>The BitOps repository contains two configuration files in the <code>.vscode/</code> directory: <code>launch.json</code> and <code>tasks.json</code>. These files are used by VSCode to configure the debugging environment.</li> <li>The new Launch button <code>Docker: bitops deploy</code> should be now available under the <code>Run &amp; Debug</code> (left panel) of VSCode</li> <li>Set the breakpoints in the code</li> <li>Run it</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>For complete code samples see https://github.com/bitovi/bitops/tree/master/docs/examples.</p> <p>Note that each directory in the examples is intended to be an Operations Repository.  For example, the files within docs/examples/bitops+eks would exist in the root of a dedicated repository.</p>"},{"location":"examples/#docker-run-examples","title":"Docker Run Examples","text":""},{"location":"examples/#selecting-environment","title":"Selecting Environment","text":"<p>An environment must always be selected <pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"dev\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p>"},{"location":"examples/#aws-config","title":"AWS Config","text":"<pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"dev\" \\\n-e AWS_ACCESS_KEY_ID=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_SECRET_ACCESS_KEY=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre>"},{"location":"examples/#passing-in-kubeconfig","title":"Passing in kubeconfig","text":"<pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"dev\" \\\n-e AWS_ACCESS_KEY_ID=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_SECRET_ACCESS_KEY=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-e KUBECONFIG_BASE64=$(cat /tmp/my-kubeconfig | base64) \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre>"},{"location":"examples/#fetch-kubeconfig-from-eks","title":"Fetch kubeconfig from EKS","text":"<p>If you have a cluster arn of <code>arn:aws:eks:us-east-1:111122223333:cluster/my-cluster</code>, you would use the following configuration: <pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"dev\" \\\n-e AWS_ACCESS_KEY_ID=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_SECRET_ACCESS_KEY=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-e CLUSTER_NAME=\"my-cluster\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p>"},{"location":"examples/#force-skip-over-ansible","title":"Force skip over ansible","text":"<p>If there is a <code>./dev/ansible/</code> directory, ansible execution can be skipped with <code>ANSIBLE_SKIP_DEPLOY=true</code>: <pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"dev\" \\\n-e AWS_ACCESS_KEY_ID=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_SECRET_ACCESS_KEY=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-e ANSIBLE_SKIP_DEPLOY=true \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p>"},{"location":"examples/#force-call-terraform-destroy","title":"Force call terraform destroy","text":"<pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"dev\" \\\n-e AWS_ACCESS_KEY_ID=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_SECRET_ACCESS_KEY=&lt;AWS_SECRET_ACCESS_KEY&gt; \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-e TERRAFORM_DESTROY=true \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre>"},{"location":"examples/#use-your-local-bitops-code","title":"Use your local BitOps code","text":"<p>If you'd like to override the BitOps code with your own version, see how to do that with the <code>$BITOPS_HOME</code> example: <pre><code>docker run \n-e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION           \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID             \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY     \\\n-e BITOPS_ENVIRONMENT=\"test\"                        \\\n-v $(pwd):/opt/bitops_deployment                    \\\n-v $BITOPS_HOME:/opt/bitops                         \\\nbitovi/bitops:latest\n</code></pre></p>"},{"location":"examples/#links-to-bitops-guides-blogs","title":"Links to Bitops Guides &amp; Blogs","text":""},{"location":"examples/#using-declarative-infrastructure-to-deploy-an-eks-cluster-and-helm-chart","title":"Using Declarative Infrastructure to Deploy an EKS Cluster and Helm Chart","text":"<ul> <li>Using Declarative Infrastructure to Deploy an EKS Cluster and Helm Chart</li> </ul>"},{"location":"examples/#bitops-and-terraform","title":"BitOps and Terraform","text":"<ul> <li>BitOps + Terraform</li> </ul>"},{"location":"examples/#combine-terraform-and-ansible-to-provision-and-configure-a-webserver","title":"Combine Terraform and Ansible to provision and configure a webserver","text":"<ul> <li>Combine Terraform and Ansible to provision and configure a webserver</li> </ul>"},{"location":"examples/#stackstorm-series","title":"StackStorm Series","text":"<ol> <li>DevOps Automation using StackStorm - Getting Started Guide</li> <li>DevOps Automation using StackStorm - Deploying with Ansible</li> <li>DevOps Automation using StackStorm - Cloud Deployment via BitOps</li> <li>DevOps Automation using StackStorm: BitOps Secrets Management</li> </ol>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#what-is-bitops","title":"What is BitOps?","text":"<p>There are 2 components to BitOps.  First, we have an Operations Repository (OpsRepo) where we store the code for our various tools. The second part is the BitOps Docker container that you can run to automate the deployment of the code in our OpsRepo.  Now with a single command, you can deploy infrastructure and software.</p> <p>The second part of BitOps is a boilerplate docker image for DevOps work. When you mount an Operations Repository to a BitOps image's <code>/opt/bitops_deployment</code> directory, BitOps will:</p> <ul> <li>Auto-detect any configuration belonging to one of its supported tools</li> <li>Loop through each tool and<ul> <li>Run any pre-execute hooks</li> <li>Read in <code>yaml</code> configuration</li> <li>Execute the tool</li> <li>Run any post-execute hooks</li> </ul> </li> </ul>"},{"location":"getting-started/#configure-bitops","title":"Configure BitOps","text":"<p>BitOps is configured in 4 steps:</p> <ol> <li>Create an Operations Repository</li> <li>Select your environment</li> <li>Configure access to your cloud provider</li> <li>Configure how you want your deployment tools to execute</li> </ol> <p>See configuration</p>"},{"location":"getting-started/#run-bitops","title":"Run BitOps","text":"<p>BitOps is packaged as a docker image and is available on docker hub.</p> <p><pre><code>docker pull bitovi/bitops\ncd $YOUR_OPERATIONS_REPO\ndocker run bitovi/bitops -v $(pwd):/opt/bitops_deployment\n</code></pre> If you need a specific version of BitOps, please check the BitOps versioning.</p>"},{"location":"getting-started/#supported-tools","title":"Supported Tools","text":"<ul> <li>Provision infrastructure with CloudFormation</li> <li>Provision infrastructure with Terraform</li> <li>Configure infrastructure with Ansible</li> <li>Deploy to Kubernetes with Helm</li> </ul>"},{"location":"getting-started/#supported-cloud-providers","title":"Supported Cloud Providers","text":"<ul> <li>Amazon Web Services (AWS)</li> <li>Microsoft Azure Cloud (Azure) - Coming soon!</li> <li>Google Cloud Engine (GCE) - Coming Soon!</li> </ul>"},{"location":"getting-started/#guides-and-other-resources","title":"Guides and Other Resources","text":"<p>BitOps already has several guides demonstrating deploying a web server or a pre-configured application using different combinations of the available BitOps tools. If you're looking for a quick start, check out some of the options available in the Examples section.</p>"},{"location":"glossary/","title":"BitOps terms","text":"Word Abbreviation(s) and Aliases Description BitOps BitOps Lifecycle Hooks hooks, before/after scripts BitOps Base Image BitOps Core Image BitOps Plugin Operations Repository Ops Repo, Operations Repo Operations Repo Environment bitops.config.yaml Configuration bitops.schema.yaml Schema Tool Omnibus Base image"},{"location":"glossary/#software-development-terms","title":"Software development terms","text":"Word Abbreviation(s) and Aliases Description"},{"location":"glossary/#general-terms","title":"General terms","text":"Word Abbreviation(s) and Aliases Description Continuous integration CI The practice of automating the integration of code changes from multiple contributors into a single software project."},{"location":"license/","title":"License","text":"<p>The MIT License (MIT)</p> <p>Copyright (c) 2020 Bitovi</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"lifecycle/","title":"Execution Lifecycle","text":""},{"location":"lifecycle/#lifecycle-hooks","title":"Lifecycle hooks","text":"<p>Within each tool directory, you can optionally have a <code>bitops.before-deploy.d/</code> and/or a <code>bitops.after-deploy.d/</code>. If any shell scripts exist within these directories, BitOps will execute them in alphanumeric order.</p> <p>This is a useful way to extend the functionality of BitOps. A popular use case we've seen is loading secrets, preparing the environment or dynamically editing <code>bitops.config.yaml</code>.</p>"},{"location":"lifecycle/#detailed-execution-flow","title":"Detailed Execution Flow","text":""},{"location":"lifecycle/#main-execution-flow","title":"Main Execution Flow","text":"<p>A single run of BitOps will:</p> <ol> <li>Copy the contents of <code>/opt/bitops_deployment</code> to a temporary working directory</li> <li>Attempt to setup a cloud provider</li> <li>If a <code>terraform/</code> directory exists within the selected environment:<ul> <li>Run any <code>bitops.before-deploy.d/*.sh</code> scripts </li> <li>Load <code>bitops.config.yaml</code> and set environment</li> <li>Merge contents with Default environment - TODO</li> <li>Select terraform version</li> <li>Run <code>terraform init</code></li> <li>Select <code>terraform workspace</code></li> <li>Run <code>terraform plan</code></li> <li>Run <code>terraform apply</code> or <code>terraform destroy</code></li> <li>Run any <code>bitops.after-deploy.d/*.sh</code> scripts</li> </ul> </li> <li>If a <code>ansible/</code> directory exists within the selected environment:<ul> <li>Run any <code>bitops.before-deploy.d/*.sh</code> scripts</li> <li>Load <code>bitops.config.yaml</code> and set environment</li> <li>Merge contents with Default environment - TODO</li> <li>Run <code>ansible-playbook playbook.yaml</code> in <code>$env/ansible/</code> </li> <li>Run any <code>bitops.after-deploy.d/*.sh</code> scripts</li> </ul> </li> <li>If a <code>helm/</code> directory exists within the selected environment:<ul> <li>Run the following for <code>$env/helm/$ENVIRONMENT_HELM_SUBDIRECTORY/</code> or for all charts in <code>$env/helm/</code><ul> <li>Run any <code>bitops.before-deploy.d/*.sh</code> scripts</li> <li>Load <code>bitops.config.yaml</code> and set environment</li> <li>Merge contents with Default environment</li> <li>Use <code>$KUBE_CONFIG_PATH</code> if defined, if not use AWS CLI to build <code>.kubeconfig</code></li> <li>Gather all values files - TODO document</li> <li>Run <code>helm dep up</code></li> <li>Run <code>helm upgrade</code> or <code>helm install</code></li> <li>Run <code>helm rollback</code> on failure</li> <li>Run any <code>bitops.after-deploy.d/*.sh</code> scripts</li> <li>TODO <code>helm_install_external_charts</code> and <code>helm_install_charts_from_s3</code> never run!</li> </ul> </li> </ul> </li> <li>If a <code>cloudformation/</code> directory exists within the selected environment:<ul> <li>Run any <code>bitops.before-deploy.d/*.sh</code> scripts</li> <li>Load <code>bitops.config.yaml</code> and set environment</li> <li>Merge contents with Default environment - TODO</li> <li>Run cfn template validation</li> <li>Create or delete cfn stack. Wait for completion</li> <li>Run any <code>bitops.after-deploy.d/*.sh</code> scripts</li> </ul> </li> </ol>"},{"location":"lifecycle/#imported-environment-variables","title":"Imported Environment Variables","text":"<p>The plugin config values and defaults are overriden by user environment variables passed to BitOps by prefixing them with <code>BITOPS_</code>. For example, <code>BITOPS_ANSIBLE_SKIP_TAGS=tag1,tag2</code> will set the plugin's config <code>ansible.cli.skip-tags</code> value to <code>tag1,tag2</code>. See Environemnt Variables Defaulting for more information.</p>"},{"location":"lifecycle/#exported-environment-variables","title":"Exported Environment Variables","text":"<p>BitOps exports the environment variables to the plugin when a ENV var name is specified in <code>bitops.schema.yaml</code> via <code>export_env</code>. This is useful for passing values to lifecycle hooks, custom scripts, or directly to the plugin executable.</p>"},{"location":"migration/","title":"Upgrade","text":"<p>Here is the list of upgrade notes for major breaking changes that you need to be aware of when migrating between the BitOps versions.</p>"},{"location":"migration/#v24","title":"v2.4","text":"<ul> <li><code>ANSIBLE_ROOT</code> ENV var in Ansible plugin was removed. Use <code>BITOPS_OPSREPO_ENVIRONMENT_DIR</code> instead, which is consistent across all plugins.</li> <li>Plugin environment variables are now automatically mapped to the plugin schema. This means that you can now use the same environment variable names as in the plugin schema. For example, if you want to override the <code>ansible.cli.skip-tags</code> value, you can now use the <code>BITOPS_ANSIBLE_SKIP_TAGS</code> environment variable. This is true for all the plugins. The precedence order is: <code>ENV</code> vars &gt; <code>bitops.config.yaml</code> values &gt; <code>bitops.config.schema.yaml</code> defaults. Keep the new convention in mind when upgrading to <code>v2.4</code> as it may clash with your existing environment variables.</li> </ul>"},{"location":"migration/#v22","title":"v2.2","text":"<ul> <li> <p>Terraform plugin <code>stack-action</code> was moved from <code>options</code> to <code>cli</code> section in <code>bitops.config.yaml</code>. You need to update your configuration from old: <pre><code>terraform:\ncli: {}\noptions:\nstack-action: \"plan\"\n</code></pre> to the new format: <pre><code>terraform:\ncli:\nstack-action: \"plan\"\noptions: {}\n</code></pre></p> </li> <li> <p>ENV variables used to skip an individual plugin deployment were updated to follow a common consistent format:</p> <ul> <li><code>SKIP_DEPLOY_TERRAFORM</code> -&gt; <code>TERRAFORM_SKIP_DEPLOY</code></li> <li><code>SKIP_DEPLOY_HELM</code> -&gt; <code>HELM_SKIP_DEPLOY</code></li> <li><code>SKIP_DEPLOY_ANSIBLE</code> -&gt; <code>ANSIBLE_SKIP_DEPLOY</code></li> <li><code>SKIP_DEPLOY_CLOUDFORMATION</code> -&gt; <code>CFN_SKIP_DEPLOY</code></li> </ul> </li> </ul>"},{"location":"migration/#v20","title":"v2.0","text":""},{"location":"migration/#bitops-core","title":"BitOps Core","text":""},{"location":"migration/#changed-environment-bitops_environment-var","title":"CHANGED: <code>ENVIRONMENT</code> -&gt; <code>BITOPS_ENVIRONMENT</code> var","text":"<p>BitOps is no longer using the <code>ENVIRONMENT</code> value, it instead uses <code>BITOPS_ENVIRONMENT</code>. Please rename your variables.</p>"},{"location":"migration/#changed-bitops_-export-prefixes","title":"CHANGED: <code>BITOPS_</code> Export Prefixes","text":"<p>BitOps core exported environment variables now have a prefix of <code>BITOPS_</code>.</p> <p>Examples</p> <ul> <li><code>BITOPS_TERRAFORM_ENV_VAR</code></li> <li><code>BITOPS_ANSIBLE_ENV_VAR</code></li> </ul>"},{"location":"migration/#changed-bitopsconfigyaml-stack-action","title":"CHANGED: <code>bitops.config.yaml</code> stack-action","text":"<p>Ops repo level <code>bitops.config.yaml</code> have had one important update; The CLI attribute <code>stack-action</code> has been added. This attribute is used to tell the BitOps plugin which method it is invoking.</p> <p>For example, the terraform plugin has 3 stack-actions: <code>plan</code>, <code>apply</code>, <code>destroy</code>.</p> <p>Old method <pre><code>terraform:\n  cli: {}\n  options:\n    command: apply\n</code></pre></p> <p>New method <pre><code>terraform:\n  cli: {}\n  options:\n    stack-action: apply\n</code></pre></p> <p>This pattern is now used by BitOps to standardize how a plugin specifies an action.</p>"},{"location":"migration/#new-default-folder-configuration","title":"NEW: Default Folder Configuration","text":"<p>A new attribute was added to <code>bitops.config.yaml</code> to define the default folder name. This attribute is evaluated when building a BitOps custom image.</p> <p>New method <pre><code>bitops:\n  default_folder: _default\n</code></pre></p> <p>The compatible environment variable to override this setting is <code>BITOPS_DEFAULT_FOLDER</code>.</p>"},{"location":"migration/#plugins","title":"Plugins","text":""},{"location":"migration/#ansible","title":"Ansible","text":"<p>depreciated attributes</p> <ul> <li><code>ansible.cli.vault_id</code></li> <li><code>ansible.cli.vault_password</code></li> <li><code>ansible.options.verbosity</code></li> </ul>"},{"location":"migration/#terraform","title":"Terraform","text":"<p>new attributes</p> <ul> <li><code>ansible.options.init-upgrade</code></li> </ul>"},{"location":"migration/#helm","title":"Helm","text":"<p>changed attributes</p> <ul> <li><code>helm.options.uninstall-charts</code> --&gt; Changed to --&gt; <code>helm.options.uninstall</code></li> <li><code>helm.options.kubeconfig.fetch.enabled</code> --&gt; Changed to --&gt; <code>helm.options.k8s.fetch.kubeconfig</code></li> </ul> <p>new attributes</p> <ul> <li><code>helm.options.default-root-dir</code></li> <li><code>helm.options.default-dir-flag</code></li> <li><code>helm.options.default-sub-dir</code></li> </ul>"},{"location":"migration/#cloudformation","title":"Cloudformation","text":"<p>changed attributes</p> <ul> <li><code>cloudformation.options.cfn-files.parameters.enabled</code> --&gt; Changed to --&gt; <code>cloudformation.options.cfn-files.parameters.template-param-flag</code></li> <li><code>cloudformation.options.cfn-files.parameters.template-file</code> --&gt; Changed to --&gt; <code>cloudformation.options.cfn-files.parameters.template-param-file</code></li> </ul> <p>new attributes</p> <ul> <li><code>cloudformation.options.s3bucket</code></li> <li><code>cloudformation.options.s3prefix</code></li> </ul>"},{"location":"operations-repo-structure/","title":"Operations Repo Structure","text":"<p>BitOps expects an operations repo to be in the following structure, where each environment is in the root of the repository.  Each environment then contains folders for each tool, and each tool has a <code>bitops.config.yaml</code>.  There are also directories that can contain before and after scripts for each tool. <pre><code>\u251c\u2500\u2500 production\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ansible\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.after-deploy.d\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.before-deploy.d\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cloudformation\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.after-deploy.d\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.before-deploy.d\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 helm\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 chartA\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 chartB\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 bitops.config.yaml\n\u2502   \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 bitops.after-deploy.d\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 bitops.before-deploy.d\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 bitops.config.yaml\n\u2514\u2500\u2500 dev\n    \u251c\u2500\u2500 ansible\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.after-deploy.d\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.before-deploy.d\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n    \u251c\u2500\u2500 cloudformation\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.after-deploy.d\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bitops.before-deploy.d\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n \u00a0\u00a0 \u251c\u2500\u2500 helm\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 chartA\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 chartB\n \u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 bitops.config.yaml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 bitops.config.yaml\n    \u2514\u2500\u2500 terraform\n        \u251c\u2500\u2500 bitops.after-deploy.d\n        \u251c\u2500\u2500 bitops.before-deploy.d\n        \u2514\u2500\u2500 bitops.config.yaml\n</code></pre></p>"},{"location":"operations-repo-structure/#environment-directories","title":"Environment Directories","text":"<p>These directories live at the root of an operations repository and are used to separate applications and environments. Depending on your use case, you may have an environment for <code>production</code>, <code>test</code> and <code>dev</code> or these traditional environments may be further separated into individual services such as <code>test_service_a</code> and <code>test_serice_b</code>. This pattern is preferential to having a branch for each environment as this allows the state of all your infrastructure to be managed from one location without merging potentially breaking an environment.</p> <p>When running BitOps, you provide the environment variable <code>BITOPS_ENVIRONMENT</code>. This tells BitOps what environment to work in for that run. A full CI/CD pipeline may call BitOps multiple times if it requires one environment to run as a pre-requisite for another.</p>"},{"location":"operations-repo-structure/#environment-directory-naming-convention","title":"Environment Directory Naming Convention","text":"<p>Sometimes it is useful to have directories in your operations repo that are not deployable environments such as common scripts that can be referenced from any environment's before or after hooks.</p> <p>BitOps allows you to name your environment directories whatever you want.  However, to better reason about which directories are environments and which aren't a good convention is to prefix any non-deployable-environment directory with an underscore (e.g. <code>_scripts</code> or <code>_terraform</code>).</p> <p>The directory <code>_default</code> is special in BitOps.  This directory is merged into your environment directory before deployment. You can control the default folder name through an environment variable <code>BITOPS_DEFAULT_FOLDER</code> or through a BitOps configuration attribute <code>bitops.default_folder</code>.</p>"},{"location":"operations-repo-structure/#tool-directories","title":"Tool directories","text":"<p>Within an environment directory are tool directories that group supported tools by name. Each of these directories is optional. For example, if your application only requires <code>terraform/</code> to execute, you do not need an <code>ansible/</code>, <code>cloudformation/</code> or <code>helm/</code> directory in your environment.</p> <p>This directory is also where you put your infrastructure code associated with the respective tool.</p> <p>Helm has additional capabilities here. You can nest multiple charts within the <code>helm/</code> directory of a given environment. BitOps will auto-detect and install these charts in alphabetical order.</p>"},{"location":"operations-repo-structure/#lifecycle-directories","title":"Lifecycle directories","text":"<p>Within a tool directory, you can optionally have a <code>bitops.before-deploy.d/</code> and/or a <code>bitops.after-deploy.d/</code>. You can put arbitrary <code>*.sh</code> scripts in here and they will be run before or after the tool executes. More for information see lifecycle docs.</p> <p>If BitOps is reporting it can't find your scripts, make sure the scripts have execute permissions. <pre><code>chmod +x bitops.before-deploy.d/*\nchmod +x bitops.after-deploy.d/*\n</code></pre></p>"},{"location":"operations-repo-structure/#bitopsconfigyaml","title":"bitops.config.yaml","text":"<p>Each tool is traditionally controlled with a set of CLI arguments. Instead of defining these CLI arguments within your pipeline configuration, these arguments can instead be defined using environment variables or within a <code>bitops.config.yaml</code> file. While the core schema for this file is common between tools, the specific properties and environment variable equivalents vary from tool to tool. See BitOps Configuration for details.</p>"},{"location":"plugins/","title":"Plugins","text":"<p>Deployment tools that BitOps can use at deploy time are called Plugins.</p> <p>A BitOps plugin is a repository with files that tell BitOps how the tool dependencies are installed into a BitOps image and how BitOps can use the tool at deploy time.</p> <p>You can create your own BitOps image to customize runtime behavior by installing your own plugins.</p> <p>Check out the bitops-plugins org in GitHub to see available plugins!</p>"},{"location":"plugins/#pre-built-images","title":"Pre-Built Images","text":"<p>BitOps' default image called <code>omnibus</code> contains BitOps <code>base</code> along with the following pre-installed plugins:</p> <ul> <li>bitops-aws-plugin</li> <li>bitops-cloudformation-plugin</li> <li>bitops-terraform-plugin</li> <li>bitops-ansible-plugin</li> <li>bitops-helm-plugin</li> <li>bitops-kubectl-plugin</li> </ul> <p>See prebuilt-config for the list of other available pre-built images and bitops images and versions to understand how these images are named and tagged on Docker Hub.</p>"},{"location":"plugins/#creating-your-own-bitops-image","title":"Creating your own BitOps image","text":"<p>To create your own BitOps, you will need two files:</p> <ul> <li>bitops.config.yaml: Contains configuration attributes that will modify how BitOps behaves</li> <li>Dockerfile: Needs to use the BitOps base image in the <code>FROM</code> directive</li> </ul>"},{"location":"plugins/#bitopsconfigyaml","title":"bitops.config.yaml","text":"<p>Best explained with an example, The default <code>bitops.config.yaml</code> looks like this: <pre><code>bitops:\n# The `bitops.config.yaml` file contains the configuration values for the BitOps core.\n#   - Changing values will require that a new image be built\n#   - Customize your BitOps image by modifying the values found in the `bitops.config.yaml`\n\nfail_fast: true     # When set, will exit if any warning+ is raised, otherwise only exit on critical error\n# LEVELS: [ DEBUG, INFO, WARNING, ERROR, CRITICAL ]\nlogging:      level: DEBUG              # Sets the logging level\ncolor:\nenabled: true           # Enables colored logs\nfilename: bitops-run      # log filename\nerr: bitops.logs          # error logs filename\npath: /var/logs/bitops    # path to log folder\n# Define the secrets to mask\nmasks:\n- # regex to search\n# looks for `BITOPS_KUBECONFIG_BASE64={string}`\nsearch:  (.*BITOPS_KUBECONFIG_BASE64.*\\=)(.*\\n)\n# replace the value part\nreplace: '\\1*******\\n'\n- # looks for `The namespace kube-system exists`\nsearch:  (.*The namespace )(kube-system)( exists.*)\n#replace kube-system\nreplace: '\\1*******\\3'\n- # see: https://regex101.com/r/44Ldz7/1\n# looks for `AWS_ACCESS_KEY_ID={string}`\nsearch: (AWS_ACCESS_KEY_ID=)(\\S+)\nreplace: \\1*******\n- # looks for `AWS_SECRET_ACCESS_KEY={string}`\nsearch: (AWS_SECRET_ACCESS_KEY=)(\\S+)\nreplace: \\1*******\ndefault_folder: _default\nplugins:  aws:\nsource: https://github.com/bitops-plugins/aws\nterraform:\nsource: https://github.com/bitops-plugins/terraform\ncloudformation:\nsource: https://github.com/bitops-plugins/cloudformation\nhelm:\nsource: https://github.com/bitops-plugins/helm\nkubectl:\nsource: https://github.com/bitops-plugins/kubectl\nansible:\nsource: https://github.com/bitops-plugins/ansible\ndeployments:\ncloudformation:\nplugin: cloudformation\nterraform:\nplugin: terraform\nhelm:\nplugin: helm\nansible:\nplugin: ansible\n</code></pre></p> <p>The repo for each plugin must be a <code>git clone</code>-able URL. The name can be anything.</p> <p>The order that plugins run is dependent on the <code>deployments</code> section. If a <code>deployments</code> section isn't provided, it will attempt to process all folders in the <code>BITOPS_ENVIRONMENT</code> directory in alphabetical order.</p>"},{"location":"plugins/#dockerfile","title":"Dockerfile","text":"<p>The only content that is needed to create a custom image is:</p> <pre><code>FROM bitovi/bitops:base\n</code></pre>"},{"location":"plugins/#creating-your-own-plugin","title":"Creating your own Plugin","text":"<p>Creating a plugin is easy, you only need 4 files:</p> <ul> <li><code>install.sh</code> - This script is called during plugin installation (Docker build time). It should be used to install any dependencies needed for your plugin to function </li> <li><code>deploy.sh</code> - The main entrypoint for your plugin at deploy time</li> <li><code>bitops.schema.yaml</code> - Defines the parameters users have access to. The corresponding <code>bitops.config.yaml</code> within the <code>BITOPS_ENVIRONMENT</code> folder will configure the parameter values.</li> <li><code>plugin.config.yaml</code> - A file used to describe the plugin configuration.</li> </ul> <p>For more information, you can look at our example plugin repo that prints your name and favorite color!</p> <p>Here is Plugin Creation guide on developing plugin locally.</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This is a BitOps roadmap. It represents our current project direction. BitOps is still a young project under brainstorming and heavy development.</p> <p>If there\u2019s something you need or have an idea, remember: this is Open Source. Create an Issue, open a Discussion, join our Community and we'll be happy to work on shaping the project's future together.</p>"},{"location":"roadmap/#backlog","title":"Backlog","text":"<ul> <li>Documentation: Getting started guide</li> <li>Documentation: BitOps vs other tools comparison</li> <li>CLI: Ops repo generator</li> <li>Plugins: Custom version pinning</li> <li>Community: Ops repo catalog</li> <li>Core: Integration tests</li> <li>Plugins: Automated testing and validation</li> <li>Core: Run a deployment sub-step per tool</li> <li>Core: Schema validation and error reporting</li> <li>Plugins: Support for private repositories</li> <li>Core: Schema validation and enhancements</li> </ul> <p>Check the <code>main</code> repository branch to see the ongoing development.</p>"},{"location":"roadmap/#release-history","title":"Release History","text":""},{"location":"roadmap/#in-development","title":"In Development","text":""},{"location":"roadmap/#done-in-v250","title":"Done in v2.5.0","text":"<ul> <li>Core: Ops repo <code>bitops.config.yaml</code> override and deployment sequence control</li> <li>Core: Unit tests</li> </ul>"},{"location":"roadmap/#done-in-v240","title":"Done in v2.4.0","text":"<ul> <li>Plugins: ENV variable mapping based on plugin schema</li> <li>Plugins: Plugin CLI command generation based on schema (beta)</li> <li>Website: Revamp with new video and list of BitOps values</li> <li>Community: Switch from Slack to Discord</li> <li>Community: Add non-stop user survey</li> </ul>"},{"location":"roadmap/#done-in-v230","title":"Done in v2.3.0","text":"<ul> <li>Security: Secrets masking</li> <li>Core: Local plugin install via <code>file://</code></li> </ul>"},{"location":"roadmap/#done-in-v220","title":"Done in v2.2.0","text":"<ul> <li>Core Real-time command output streaming</li> <li>Code <code>pylint</code> static code analyser for improving the python standards</li> </ul>"},{"location":"roadmap/#done-in-v210","title":"Done in v2.1.0","text":"<ul> <li>Community: Start bi-weekly BitOps Community Meetings</li> <li>Plugins: Package the latest tools versions by default in the official BitOps image</li> <li>Code: Introduce <code>black</code> tool for enforcing the common python code formatting style</li> </ul>"},{"location":"roadmap/#done-in-v200","title":"Done in v2.0.0","text":"<ul> <li>Core: Rewrite the engine with Python instead of bash</li> <li>Plugins: New system to compose the BitOps image with the custom tools</li> <li>Plugins: Plugins catalog github.com/bitops-plugins</li> <li>Images: New official images: omnibus, aws-ansible, aws-terraform, aws-helm</li> <li>Releases: New docker tagging strategy</li> </ul>"},{"location":"roadmap/#done-in-v100","title":"Done in v1.0.0","text":"<ul> <li>Ops Repository concept</li> <li>Initial implementation in bash</li> </ul>"},{"location":"versioning/","title":"Versioning","text":""},{"location":"versioning/#tools","title":"Tools","text":"<p>We package the latest versions of the tools that are available at a release time for the official BitOps Docker images. Check out BitOps Releases to understand which versions are currently shipped.</p> <p>If you need specific versions or tools, you can build your own image with the custom plugins.</p>"},{"location":"versioning/#images","title":"Images","text":"<p>BitOps Docker images are packaged and hosted on Docker Hub. Here is how these images are named, versioned and tagged.</p> <ul> <li>An image with a version tag containing a semver (e.g. <code>2.0.0</code>) is immutable and refers to the stable release.</li> <li>A version tag equal to <code>latest</code> is always mutable and points to the latest stable release.</li> <li>A version tag containing <code>dev</code> is always mutable and refers to the current development state in the <code>main</code> repository branch.</li> <li>A version tag containing <code>omnibus</code> points to the default image that includes recommended DevOps tools.</li> <li>A version tag containing <code>base</code> refers to a minimal image with no other tools. You can build a custom BitOps image from it.</li> </ul>"},{"location":"versioning/#official-images","title":"Official Images","text":"<p>To clear up any potential confusion regarding the versioning of the <code>bitovi/bitops</code> image, we use the following table.</p> Image Name PreInstalled Tools Docker image name Supported Cloud provider Additional stable image tags Development image tags (<code>main</code> branch) omnibus Terraform  Cloudformation  Ansible  Helm  Kubectl  AWS CLI <code>bitovi/bitops:2.0.0-omnibus</code> AWS <code>latest</code> <code>2.0.0</code> <code>dev</code> aws-terraform Terraform  AWS CLI <code>bitovi/bitops:2.0.0-aws-terraform</code> AWS aws-ansible Ansible  AWS CLI <code>bitovi/bitops:2.0.0-aws-ansible</code> AWS aws-helm Helm  Terraform  AWS CLI <code>bitovi/bitops:2.0.0-aws-helm</code> AWS base BitOps source <code>bitovi/bitops:2.0.0-base</code> - <code>base</code> <code>dev-base</code>"},{"location":"versioning/#image-tag-pinning","title":"Image tag pinning","text":"<ul> <li>We always recommend pinning the stable version of BitOps to avoid any breaking changes like <code>bitovi/bitops:2.0.0</code>.</li> <li>If the security is higher priority for you, use sha256 digest like <code>bitovi/bitops:sha256:82becede498899ec668628e7cb0ad87b6e1c371cb8a1e597d83a47fac21d6af3</code>.</li> </ul> <p>See more in the docker documentation.</p>"},{"location":"cloud-configuration/configuration-aws/","title":"AWS","text":"<p>\u26a0\ufe0f Note from the developers: We are currently in the process of moving our documentation and so the below documentation is only partially correct. For more information on this tool please check out our plugin documentation.</p>"},{"location":"cloud-configuration/configuration-aws/#aws","title":"AWS","text":"<p>\u26a0\ufe0f <code>bitops.config.yaml</code> is not yet supported for AWS (TODO). All configurations must be done with environment variables.</p>"},{"location":"cloud-configuration/configuration-aws/#configuration","title":"Configuration","text":"Item BitOps Property Environmental Variable Description Default Required aws_access_key_id TODO AWS_ACCESS_KEY_ID Specifies an AWS access key associated with an IAM user or role. See AWS official documentation <code>null</code> Yes aws_secret_access_key TODO AWS_SECRET_ACCESS_KEY Specifies the secret key associated with the access key. This is essentially the \"password\" for the access key. See AWS official documentation <code>null</code> Yes aws_default_region TODO AWS_DEFAULT_REGION Specifies the AWS Region to send the request to. See AWS official documentation <code>null</code> Yes aws_session_token TODO AWS_SESSION_TOKEN Specifies the session token value that is required if you are using temporary security credentials that you retrieved directly from AWS STS operations. See AWS official documentation <code>null</code> No"},{"location":"cloud-configuration/configuration-azure/","title":"Microsoft Azure","text":"<p>The following environment variables for Microsoft Azure are required. See Microsoft Azure official documentation for how to create them.</p> <p>All configurations must be done with environmental variables</p>"},{"location":"cloud-configuration/configuration-azure/#configuration","title":"Configuration","text":"Item BitOps Property Environmental Variable Description Default Req AZ_CLIENT_ID AZ_CLIENT_ID <code>null</code> Yes AZ_CLIENT_SECRET AZ_CLIENT_SECRET <code>null</code> Yes AZ_SUBSCRIPTION_ID AZ_SUBSCRIPTION_ID <code>null</code> Yes AZ_TENANT_ID AZ_TENANT_ID <code>null</code> Yes"},{"location":"cloud-configuration/configuration-gcp/","title":"GCP","text":"<p>Follow the steps in Google's documentation to create and download your GCP Authentication Key.  See Google's official documentation</p>"},{"location":"cloud-configuration/configuration-gcp/#configuration","title":"Configuration","text":"Item BitOps Property Environmental Variable Description Default Req GOOGLE_AUTHENTICATION_KEY GOOGLE_AUTHENTICATION_KEY <code>null</code> Yes"},{"location":"development/DCO/","title":"DCO","text":"<p>Developer Certificate of Origin Version 1.1</p> <p>Copyright (C) 2004, 2006 The Linux Foundation and its contributors. 1 Letterman Drive Suite D4700 San Francisco, CA, 94129</p> <p>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.</p> <p>Developer's Certificate of Origin 1.1</p> <p>By making a contribution to this project, I certify that:</p> <p>(a) The contribution was created in whole or in part by me and I     have the right to submit it under the open source license     indicated in the file; or</p> <p>(b) The contribution is based upon previous work that, to the best     of my knowledge, is covered under an appropriate open source     license and I have the right under that license to submit that     work with modifications, whether created in whole or in part     by me, under the same open source license (unless I am     permitted to submit under a different license), as indicated     in the file; or</p> <p>(c) The contribution was provided directly to me by some other     person who certified (a), (b) or (c) and I have not modified     it.</p> <p>(d) I understand and agree that this project and the contribution     are public and that a record of the contribution (including all     personal information I submit with it, including my sign-off) is     maintained indefinitely and may be redistributed consistent with     this project or the open source license(s) involved.</p>"},{"location":"development/development/","title":"Development Guide","text":"<p>We are excited for any contributions from the community, we welcome any feedback whether its:</p> <ul> <li>Submitting a bug report</li> <li>An idea for feature development</li> <li>Expanding the functionality of an existing feature</li> <li>Submitting an example guide or blog using Bitops</li> <li>Security or other concerns</li> </ul> <p>When contributing to BitOps, please consider some of the following basic guidelines before submitting.</p>"},{"location":"development/development/#requirements","title":"Requirements","text":"<p>To submit changes we require that all contributions first have a GitHub issue created where submissions can be discussed and visible to all Contributors and Maintainers.</p> <p>By contributing, you agree to the Developer Certificate of Origin (DCO) which states that the code being submitted is owned wholly by you.</p> <p>Contributors and Maintainers are expected to treat other community members with courtesy and respect, be willing and able to accept constructive criticism, and strive for understanding of other's viewpoints in all community channels.</p>"},{"location":"development/development/#building-bitops","title":"Building BitOps","text":"<p>Before continuing, if you haven't used GitHub before you may want to review GitHub's forking guide and cloning guide which further explains how to clone a repo for any major operating system.</p> <p>To develop BitOps, first fork BitOps to create a copy of the BitOps GitHub repo under your own account:</p> <p></p> <p>Then you need to clone your personal copy of the repository you just forked. Clicking the green <code>Code</code> button on your repo will give you a copiable URL to use:</p> <pre><code>git clone git@github.com:&lt;your github username&gt;/&lt;repository-name&gt;.git\ncd bitops\ngit checkout -b your-branch-name\n</code></pre> <p>Replace <code>your-branch-name</code> with the name of the feature you're building, e.g. <code>git checkout -b some-ansible-feature</code> to create a <code>some-ansible-feature</code> branch.</p> <p>As you're forking the code to work locally, you may not need or wish to create a separate branch, however, BitOps will not allow commits directly to <code>main</code> and it's just a good habit to get into!</p> <p>Then after modifying the code or adding your changes, re-build the BitOps docker image:</p> <pre><code>docker build bitops --tag bitovi/bitops:ansible-feature\n</code></pre> <p>You can now execute your modified version of BitOps locally to test your changes.</p> <p>For example, to test your new <code>ansible-feature</code> version of BitOps with an Operations Repo environment named <code>ansible-operations-repo</code> containing an Ansible playbook and other data:</p> <pre><code>export AWS_ACCESS_KEY_ID=ABCDEF012345\nexport AWS_SECRET_ACCESS_KEY=ZYXWV09876\nexport AWS_DEFAULT_REGION=us-east-1\nexport MY_VAR1=value1\ndocker run \\\n-e BITOPS_ENVIRONMENT=\"ansible-operations-repo\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION \\\n-e MY_VAR1=$MY_VAR1 \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:ansible-feature\n</code></pre>"},{"location":"development/development/#understanding-bitops","title":"Understanding Bitops","text":"<p>BitOps has several packages and environment variables readily available which makes working with BitOps easy.</p>"},{"location":"development/development/#standard-bitops-environmental-variables","title":"Standard Bitops Environmental Variables","text":"<p>A <code>*</code> denotes a required variable.</p> Variable Value Notes <code>$BITOPS_DIR</code> <code>/opt/bitops</code> Within the container the default working directory for BitOps <code>$BITOPS_ENVIRONMENT</code>* <code>YOUR_OPS_REPO_ENVIRONMENT</code> BitOps requires at least one environment folder to be specified at container execution. <code>$BITOPS_ENVROOT</code> <code>$BITOPS_TEMPDIR/$BITOPS_ENVIRONMENT</code> e.g <code>/tmp/tmp.RANDOM/YOUR_OPS_REPO_ENVIRONMENT</code> <code>$BITOPS_TEMPDIR</code> <code>/tmp/tmp.RANDOM</code> This is the randomly generated working dir for BitOps. <code>$BITOPS_DEFAULT_ROOT_DIR</code> <code>/opt/bitops_deployment</code> This working dir for BitOps (moved to <code>$BITOPS_TEMPDIR</code> during execution)"},{"location":"development/development/#standard-bitops-packages","title":"Standard BitOps Packages","text":"<p>Packages natively available in a running BitOps container:</p> <ul> <li>ansible</li> <li>aws / awscli</li> <li>curl</li> <li>git</li> <li>shyaml</li> <li>pip</li> <li>rsync</li> <li>jq</li> <li>unzip</li> <li>wget</li> </ul> <p>For the most up-to-date list, see Dockerfile and requirements.txt.</p> <p>The BitOps repo is fairly straightforward in its current implementation. See <code>scripts/plugins/</code> written in Python for most of the logic responsible for running the pipelines that tie together deployment tools like <code>aws</code>, <code>ansible</code>, <code>terraform</code> which are called BitOps plugins.</p> <p>Additionally, plugins are separated git repositories with instructions about installing the specific tool and running it. If you'd like to add support for the new tool to BitOps, take a look at creating your own plugin.</p>"},{"location":"development/development/#creating-a-pr","title":"Creating a PR","text":"<p>Once you have finished testing your code, please ensure you have first created an issue related to the feature you are developing.</p> <p>After you ran <code>git add</code> and <code>git commit</code>, push your new branch to Github:</p> <pre><code>git push --set-upstream origin some-ansible-feature\n</code></pre> <p>Once your code has been submitted to Github, navigate to the main BitOps Github page, and click the \u201cNew Pull Request\u201d button. You'll want the original BitOps repo you forked from not your personal/modified one.</p> <p>Select <code>Compare across forks</code> and then select your branch name e.g <code>some-ansible-feature</code> as the 'compare' branch to attempt to merge. You may be warned about conflicts when merging the code, Github will try to tell you what is incorrect.</p> <p>If you are having issues creating a Pull from your forked repo, GitHub has a more thorough guide than what is presented here.</p> <p>If you're unable to solve the merge conflicts, don't worry you'll still be able to submit your PR, just make a note of the issues you were facing in the PR description and we will work with you to solve them.</p> <p>Give your PR a meaningful title and provide details about the change in the description, including a link to the issue(s) relating to your PR. All that's left is to click the 'Create pull request' button and wait for our eager review of your code!</p>"},{"location":"development/development/#python-style-guide","title":"Python Style guide","text":"<ul> <li>Use 4 spaces for a tab.</li> <li>We use <code>black</code> code formatter which automatically enforces consistent style on the whole code base.</li> <li>You can verify that your modifications don\u2019t break any rules by running the lint script - <code>tox -e black</code>.</li> <li>You can autoformat the python code by running <code>black</code> manually or by configuring your favorite editor to do it for you. Here is an example for VSCode.</li> <li>Pylint is used as a static code analyzer for quick checking for common mistakes and enhancing the python coding standards. You can run it with <code>tox -e pylint</code>. You can enable pylint in VSCode and other IDEs.</li> </ul>"},{"location":"development/development/#bash-style-guide","title":"Bash Style guide","text":"<p>The BitOps container uses the Bourne shell during execution, please ensure all functions used in your submission exist for <code>sh</code>. Submissions that utilize alternate shells (<code>zsh</code>,<code>ksh</code>,<code>csh</code>, etc.) will not be accepted.</p> <p>BitOps comes packaged with <code>shyaml</code> which can be used to parse YAML config files from stdout.</p> <p>When contributing Bash code segments to BitOps please keep these concepts in mind:</p> <ul> <li>Use 2 spaces for a tab.</li> <li>Add <code>echo</code> statements during plugin execution to give verbosity and debugging during execution</li> <li>Update any related documentation to the code or feature you are modifying</li> <li>Avoid multiple commands per line if possible. Replace <code>;</code> with whitespace and newline characters where appropriate.</li> <li>For scripts or other subroutines use <code>_</code> to connect multiple word names, e.g <code>validate_env.sh</code></li> </ul>"},{"location":"development/development/#yaml-style-guide","title":"YAML Style guide","text":"<p>BitOps uses standard YAML formatting with only a few recommendations regarding style:</p> <ul> <li>When adding additional YAML files, utilize the full <code>.yaml</code> file extension</li> <li>For multi-word variable names use <code>-</code> hyphen to connect them, e.g <code>cfn-stack-name.yaml</code></li> </ul>"},{"location":"development/local-plugin-creation/","title":"Plugin creation guide","text":"<p>So you wanna build a BitOps plugin, eh?  Follow along for how to do it locally!</p>"},{"location":"development/local-plugin-creation/#1-create-a-plugin-repo","title":"1. Create a plugin repo","text":"<pre><code>cd /path/to/bitops-plugins\nmkdir sample-plugin &amp;&amp; cd sample-plugin\n</code></pre> <p>More information on what goes in a plugin here.</p> <p>Note: If the plugin needs to install tools, you will need to build and run a local version of BitOps.  The first portion of this guide assumes the install.sh script DOES NOT needs to be run.  For more information about how to set up BitOps for local development with a plugin that requires an installation, skip to step 5 below.</p> <p>For this example, we'll keep to a really simple plugin.</p> <p>To start with, create a file called <code>bitops.schema.yaml</code> and add the following content.</p> <pre><code># /path/to/bitops-plugins/bitops.schema.yaml\n\nsample-plugin:\noptions:\ntype: object\nproperties:\nfoo:\ntype: string\nexport_env: SAMPLE_PLUGIN_FOO\nrequired: true\ndefault: foo_value\n</code></pre> <p>Next, create a simple <code>deploy.sh</code> script.  This script does some checks and shows how to use some of the system <code>BITOPS_</code> available environment variables then outputs configuration values defined by the <code>bitops.schema.yaml</code> in <code>cli</code> and <code>options</code> sections.</p> <pre><code># /path/to/bitops-plugins/deploy.sh\n\n#!/bin/bash\nset -e\n\necho \"Running Sample Plugin deployment script...\"\n\n# vars\nexport BITOPS_SCHEMA_ENV_FILE=\"$BITOPS_OPSREPO_ENVIRONMENT_DIR/ENV_FILE\"\n\nif [ ! -d \"$BITOPS_OPSREPO_ENVIRONMENT_DIR\" ]; then\necho \"No sample-plugin directory. Skipping.\"\nexit 0\nfi\n\necho \"Deploying sample-plugin...\"\n\nif [ ! -f \"$BITOPS_SCHEMA_ENV_FILE\" ]; then echo \"No sample-plugin ENV file found\"\nelse\nsource \"$BITOPS_SCHEMA_ENV_FILE\"\nfi\n\ncd $BITOPS_OPSREPO_ENVIRONMENT_DIR\n\necho \"Listing contents of sample-plugin Root: $BITOPS_OPSREPO_ENVIRONMENT_DIR\"\nls -al .\n\necho \"Running the plugin CLI: (SKIPPED)\"\n\necho \"Options:\"\necho \"SAMPLE_PLUGIN_FOO: $SAMPLE_PLUGIN_FOO\"\n# Expected result: \"foo_value\"\n</code></pre> <p>Note: Much of the above is best practice boilerplate and is not strictly necessary.</p> <p>Finally, create a <code>plugin.config.yaml</code> to configure how BitOps uses the plugin:</p> <pre><code># /path/to/bitops-plugins/plugin.config.yaml\n\nplugin:\ndeployment:\nlanguage: bash\ndeployment_script: deploy.sh\n</code></pre>"},{"location":"development/local-plugin-creation/#2-create-an-ops-repo-for-testing","title":"2. Create an ops repo for testing","text":"<p>Now we'll create an <code>ops-repo</code> and <code>environment</code> with a directory that matches your tool:</p> <ul> <li>In this example, we have an <code>sample-ops-repo</code> dir as the root. </li> <li><code>test-env</code> is our new environment that we want to test the plugin on.</li> <li>Finally we have a directory for the <code>sample-plugin</code> plugin itself:</li> </ul> <pre><code>mkdir -p /path/to/sample-ops-repo/test-env/sample-plugin\ncd /path/to/sample-ops-repo/test-env/sample-plugin\n</code></pre> <p>Populate the tool's <code>bitops.config.yaml</code> based on the schema defined above:</p> <pre><code># /path/to/sample-ops-repo/test-env/sample-plugin/bitops.config.yaml\n\nsample-plugin:\noptions:\nfoo: baz\n</code></pre>"},{"location":"development/local-plugin-creation/#3-test-your-plugin","title":"3. Test your plugin","text":""},{"location":"development/local-plugin-creation/#31-bitops-level-bitops-config","title":"3.1. BitOps-level BitOps Config","text":"<p>To test your plugin, you'll need BitOps to run with a <code>bitops.config.yaml</code> that has your plugin defined in the <code>deployments</code>.</p> <p>Create a <code>bitops.config.yaml</code> at the <code>test-env</code> level in your <code>sample-ops-repo</code>, and add a <code>plugins</code> and <code>deployments</code> reference to your plugin:</p> <ul> <li>Note the <code>file:///opt/...</code> path in the example. This is the path that will result when the plugin is installed into the BitOps Docker container running it - NOT the path on your local machine.</li> </ul> <pre><code># /path/to/sample-ops-repo/test-env/sample-plugin/bitops.config.yaml\n\nbitops:\nplugins:    sample-plugin: file:///opt/bitops/scripts/installed_plugins/sample-plugin\ndeployments:\nsample-plugin:\nplugin: sample-plugin\n</code></pre>"},{"location":"development/local-plugin-creation/#32-run-your-test","title":"3.2. Run your test","text":"<p>To run BitOps against a local plugin, you'll need to mount the plugin to the location BitOps expects plugins to be:</p> <ol> <li>Create a <code>_scripts</code> folder at the root level of your <code>ops-repo</code> dir.</li> <li>Create a <code>deploy.local.sh</code> file to script the upcoming <code>docker run</code> command.</li> <li> <p>Make sure to <code>chmod +x</code> the deploy script.</p> <pre><code># in /path/to/sample-ops-repo\nmkdir _scripts &amp;&amp; cd _scripts\ntouch deploy.local.sh\nchmod +x deploy.local.sh\n</code></pre> </li> <li> <p>Create a <code>.gitignore</code> to keep the deploy file out of the upstream repo:</p> <pre><code># in /path/to/sample-ops-repo\necho _scripts/deploy.local.sh &gt;&gt; .gitignore\n</code></pre> <p>&lt;!--</p> <p>Note: To see the full code so far, see docs/examples/plugin-examples/plugin-no-install/duplicate-environment --&gt;</p> </li> <li> <p>Copy this content into <code>deploy.local.sh</code>:</p> <pre><code>#!/bin/bash\n\ndocker run --rm --name bitops \\\n-e BITOPS_ENVIRONMENT=\"test-env\" \\\n-v /path/to/sample-ops-repo:/opt/bitops_deployment \\\n-v /path/to/bitops-plugins/sample-plugin:/opt/bitops/scripts/installed_plugins/sample-plugin \\\nbitovi/bitops:latest\n</code></pre> <p>Note the docker-context name of the plugin dir <code>/path/to/bitops-plugins/sample-plugin:/opt/bitops/scripts/installed_plugins/***sample-plugin***</code> must exactly match the name in <code>/path/to/bitops-plugins/bitops.schema.yaml</code>:</p> <pre><code>sample-plugin:\n</code></pre> </li> <li> <p>Run it!</p> <pre><code> # in /path/to/sample-ops-repo/_scripts\n./deploy.local.sh\n</code></pre> <p>If things go well, the output should look like this:</p> <pre><code>&gt; ./deploy.local.sh\n2023-05-15 18:37:12,675 bitops-logger WARNING Optional file was not found. Consider adding the following file:\n [/opt/bitops/scripts/installed_plugins/azure/plugin.config.yaml]\nRunning Azure Plugin deployment script...\nDeploying azure plugin...\nNo azure plugin ENV file found\nListing contents of azure plugin Root: /tmp/tmpj5lv41jw/test-env/azure\ntotal 12\ndrwxr-xr-x    2 root     root          4096 May 15 16:19 .\ndrwxr-xr-x    3 root     root          4096 May 15 18:11 ..\n-rw-r--r--    1 root     root            31 May 15 18:36 bitops.config.yaml\nRunning the plugin CLI: (SKIPPED)\nOptions:\nAZURE_FOO: foo_value\nBitOps has finished!\n</code></pre> </li> </ol>"},{"location":"development/local-plugin-creation/#4-handling-the-plugin-install-script","title":"4. Handling the Plugin Install Script","text":"<p>If your new plugin needs to run some install scripts (e.g. to install a CLI tool), you'll need to build your own version of BitOps locally.</p> <p>Note: For more information on how to do this, see plugins.</p>"},{"location":"development/local-plugin-creation/#41-update-the-plugin-to-add-an-install-script","title":"4.1 Update the Plugin to Add an Install Script","text":"<p>Add the <code>install</code> configuration to your plugin's <code>plugin.config.yaml</code></p> <pre><code>plugin:\n# this plugin has install instructions\ninstall: language: bash\ninstall_script: install.sh\n\ndeployment:\nlanguage: bash\ndeployment_script: deploy.sh\n</code></pre> <p>Create your install script:</p> <pre><code># /path/to/bitops-plugins/install.sh\n\n#!/bin/bash\nset -e\n\necho \"In the install script for the sample-plugin\"\n\napk update &amp;&amp; apk upgrade\n# add your actual installers here\n</code></pre>"},{"location":"development/local-plugin-creation/#42-build-a-bitops-image","title":"4.2. Build a BitOps image","text":"<p>Create a new directory to hold your custom BitOps config. </p> <p>In this case we're putting it in our <code>bitops-plugins</code> parent dir, but you could put it anywhere.</p> <pre><code>IMAGE_PATH=/path/to/bitops-plugins/bitops-images/sample-plugin-image\n\nmkdir -p $IMAGE_PATH &amp;&amp; cd $IMAGE_PATH\n</code></pre>"},{"location":"development/local-plugin-creation/#421-add-the-bitops-config","title":"4.2.1 Add the BitOps config","text":"<p>First, add your BitOps level <code>bitops.config.yaml</code> and include a reference to your local file dependency via the <code>plugins</code> and  <code>deployments</code> sections:</p> <pre><code># /path/to/bitops-plugins/bitops-images/sample-plugin-image/bitops.config.yaml\n# Note that again these are docker-context paths, not local paths.\n\nbitops:\nplugins:    sample-plugin:\nsource: file:///opt/bitops-local-plugins/sample-plugin\ndeployments:\nsample-plugin:\nplugin: sample-plugin\n</code></pre> <p>Note: This is the same file as above (<code>/path/to/ops-repo/test-env/sample-plugin/bitops.config.yaml</code>), but we've updated the <code>plugins.sample-plugin</code> object to include a <code>file://</code> source.</p> <p>Note: The path of the source is reserved by BitOps for locally developed plugins.  When you build a custom BitOps image, if there is a <code>plugins</code> directory as a sibling to the <code>Dockerfile</code>, BitOps will copy that file into the container at <code>/opt/bitops-local-plugins</code>.</p>"},{"location":"development/local-plugin-creation/#422-add-your-dockerfile","title":"4.2.2 Add your Dockerfile","text":"<pre><code># /path/to/bitops-plugins/bitops-images/sample-plugin-image/Dockerfile\n\nFROM bitovi/bitops:base\n</code></pre>"},{"location":"development/local-plugin-creation/#423-copy-plugin-code-to-the-bitops-directory","title":"4.2.3 Copy plugin code to the BitOps directory","text":"<p>In order for the build to have access to your local plugin files, they'll need to be in the same directory as the <code>Dockerfile</code>.  One quick way to do this is to set up a simple script to run prior to your docker build to clean and re-copy the plugin files:</p> <pre><code># /path/to/bitops-images/copy-plugins.sh\n\n#!/bin/bash\n\nPLUGIN_NAME=sample-plugin\nPLUGIN_ROOT_PATH=/path/to/bitops-plugins\n\nCUSTOM_IMAGE_PATH=\"$PLUGIN_ROOT_PATH/bitops-images/$PLUGIN_NAME-plugin-image\"\nPLUGIN_PATH=\"$PLUGIN_ROOT_PATH/$PLUGIN_NAME\"\n\nmkdir -p \"$CUSTOM_IMAGE_PATH/plugins\"\n\n# clean and copy to the image build dir\nrm -rf $CUSTOM_IMAGE_PATH/plugins/$PLUGIN_NAME\ncp -r $PLUGIN_PATH \"$CUSTOM_IMAGE_PATH/plugins/$PLUGIN_NAME\"\n</code></pre>"},{"location":"development/local-plugin-creation/#424-build-the-image","title":"4.2.4 Build the image","text":"<pre><code>./copy-plugins.sh\n\ndocker build --tag bitovi/bitops:local-sample-plugin --no-cache .\n</code></pre>"},{"location":"development/local-plugin-creation/#425-test-your-plugin","title":"4.2.5. Test your plugin","text":"<pre><code>PATH_ROOT=~/Bitovi/github/bitops-plugins # modify to your path here\n\ndocker run --rm --name bitops \\\n-e BITOPS_ENVIRONMENT=\"test-env\" \\\n-v $PATH_ROOT/sample-ops-repo:/opt/bitops_deployment \\\n-v $PATH_ROOT/sample-plugin:/opt/bitops/scripts/installed_plugins/sample-plugin \\\nbitops:local-sample-plugin\n</code></pre>"},{"location":"development/local-plugin-creation/#5-fully-remote-development","title":"5. Fully Remote Development","text":"<p>An alternative to local plugin development is to host the plugin code remotely and specify the plugin via url instead of <code>file://</code> like:</p> <pre><code>bitops:\nplugins:    sample-plugin:\nsource: https://github.com/your-org/sample-plugin\ndeployments:\nsample-plugin:\nplugin: sample-plugin\n</code></pre> <p>Then, you can follow the steps in #5 above (without the <code>copy-plugins.sh</code> script).</p>"},{"location":"examples/bitops%2Bcloudformation-blog/","title":"Bitops Operations Repo","text":"<p>Welcome to Bitops! This serves as a starting point for deploying your application to the cloud.</p> <p>This repo can be run as is with <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=\"us-east-2\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops%2Beks/","title":"Bitops Operations Repo","text":"<p>Welcome to Bitops! This serves as a starting point for deploying your application to the cloud.</p> <p>This repo can be run as is with <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/","title":"Secrets Management","text":"<p>A set of scripts to ease secrets management.</p>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS CLI (and an AWS account)</li> <li>yq (Mac: <code>brew install yq</code>)</li> </ul>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#common-environment-variables","title":"Common Environment Variables","text":"<p>These environment variables apply to all scripts</p> <ul> <li><code>AWS_SECRETS_REGION</code></li> <li>Description: The AWS region the secret resides in</li> <li>Default: <code>AWS_DEFAULT_REGION</code></li> <li><code>AWS_SECRETS_OUTPUT</code></li> <li>Description: The output format of the underlying AWS commands</li> <li>Default: <code>yaml</code></li> </ul>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#best-practices","title":"Best Practices","text":""},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#naming","title":"Naming","text":"<p>It is best to name each secret something that is scoped to its use.</p> <p>To be consistent, the convention should be: <pre><code>${operations repo name}/${operations repo environment}/${operations repo tool}\n</code></pre></p>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#naming-for-helm","title":"Naming for helm","text":"<p>For helm secrets, name the secret according to the full path of the tool.</p> <p>For example, an ops repo secret for the Grafana deployment in the <code>dev-tools</code> environment might be called: <code>operations-staffing-app/dev-tools/helm/grafana</code></p>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#guide","title":"Guide","text":"<p>Let's say you have a tool called <code>dev/helm/my-deployment</code>.</p>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#creating-the-secret","title":"Creating the secret","text":"<p>Create a <code>.yaml</code> file locally called <code>values-secrets.yaml</code> which contains a subset of the helm chart values for <code>my-deployment</code>, and place it next to the same tool's <code>values.yaml</code> file.</p> <p><code>operations-staffing-app/dev/helm/my-deployment/values-secrets.yaml</code> <pre><code>password: foo\n</code></pre></p> <p>Note: Files named <code>values-secrets.yaml</code> are git ignored and will not be checked in.</p> <p>Save the secret in AWS: <pre><code>cd /path/to/operations-staffing-app\nAWS_SECRETS_REGION=\"us-west-1\" \\\nAWS_SECRETS_SECRET_NAME=\"operations-staffing-app/dev/helm/my-deployment\" \\\nAWS_SECRETS_SECRET_DESCRIPTION=\"Secrets for operations-staffing-app/dev/helm/my-deployment\" \\\nAWS_SECRETS_SECRET_FILE=\"operations-staffing-app/dev/helm/my-deployment/values-secrets.yaml\" \\\n./_scripts/secrets/aws/save-file.sh\n</code></pre></p>"},{"location":"examples/bitops%2Bfast%2Breact%2Bstatic%2Brenderer/_scripts/secrets/aws/#include-the-secret-in-the-deployment","title":"Include the secret in the deployment","text":"<p>Create a before script in the helm chart directory: <code>operations-staffing-app/dev/helm/my-deployment/bitops.before-deploy.d/fetch-secrets.sh</code> <pre><code>#!/bin/bash\nset -e\n\nAWS_SECRETS_REGION=\"us-west-1\" \\\nAWS_SECRETS_SECRET_NAME=\"operations-staffing-app/dev/helm/my-deployment\" \\\nAWS_SECRETS_SECRET_FILE=\"$HELM_CHART_DIRECTORY/values-secrets.yaml\" \\\n$ROOT_DIR/_scripts/secrets/aws/get-file.sh\n</code></pre></p> <p>Note: Ensure the file is executable with <code>chmod +x &lt;file&gt;</code></p> <p>BitOps will then see the <code>values-secrets.yaml</code> at deploy time and include it into the helm deployment.</p>"},{"location":"examples/bitops%2Bhelm-blog/","title":"Bitops Operations Repo","text":"<p>Welcome to Bitops! This serves as a starting point for deploying your application to the cloud.</p> <p>This repo can be run as is with <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=\"us-east-2\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/","title":"Bitops Operations Repo","text":"<p>Welcome to Bitops! This serves as a starting point for deploying StackStorm to the cloud.</p> <p>This repo can be run as is with <pre><code>export AWS_ACCESS_KEY_ID=ABCDEF012345 \nexport AWS_SECRET_ACCESS_KEY=8BuJW2LIlQaTvInalkq0Xzu5ogcf \nexport AWS_DEFAULT_REGION=us-west-1 \nexport TF_STATE_BUCKET=st2-bitops-bucket \nexport ST2_GITHUB_TOKEN=wL/SK5g37dz6GqL07YEXKObR6 \ndocker run \\ \n-e ENVIRONMENT=\"st2-bitops-test\" \\ \n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\ \n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\ \n-e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION \\ \n-e TF_STATE_BUCKET=$TF_STATE_BUCKET \\ \n-e ST2_GITHUB_TOKEN=$ST2_GITHUB_TOKEN \\ \n-v $(pwd):/opt/bitops_deployment \\ \nbitovi/bitops:latest\n</code></pre></p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/","title":"Ansible-st2","text":"<p>Ansible playbooks to deploy StackStorm.</p> <p>StackStorm is event-driven automation platform written in Python. With over 50+ integrations like GitHub, Docker, Nagios, NewRelic, AWS, Ansible it allows you to wire together your existing infrastructure into complex Workflows with auto-remediation and many more. Aka IFTTT orchestration for Ops.</p> <p> </p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#supported-platforms","title":"Supported platforms","text":"<ul> <li>Ubuntu Xenial (16.04)</li> <li>Ubuntu Bionic (18.04)</li> <li>RHEL7 / CentOS7</li> <li>RHEL8 / CentOS8</li> </ul> <p>If you're using the provided Vagrantfile, note that it uses Bionic by default.</p> <p>In order to access StackStorm Web UI, please don't forget to ensure that http/https ports are opened in your firewall system.</p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#requirements","title":"Requirements","text":"<p>At least 2GB of memory and 3.5GB of disk space is required, since StackStorm is shipped with RabbitMQ, Mongo and nginx.</p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#installation","title":"Installation","text":"<pre><code># stackstorm\nansible-playbook stackstorm.yml\n</code></pre>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#variables","title":"Variables","text":"<p>Below is the list of variables you can redefine in your playbook to customize st2 deployment:</p> Variable Default Description st2repo <code>st2repo_name</code> <code>stable</code> StackStorm PackageCloud repository to install. <code>stable</code>, <code>unstable</code>, <code>staging-stable</code>, <code>staging-unstable</code> st2 <code>st2_version</code> <code>latest</code> StackStorm version to install. <code>present</code> to install available package, <code>latest</code> to get automatic updates, or pin it to numeric version like <code>2.2.0</code>. <code>st2_revision</code> <code>1</code> StackStorm revision to install. Used only with pinned <code>st2_version</code>. <code>st2_config</code> <code>{}</code> Hash with StackStorm configuration settings to set in <code>st2.conf</code> ini file. <code>st2_system_user</code> <code>stanley</code> System user from which st2 will execute local/remote shell actions. <code>st2_system_user_in_sudoers</code> <code>yes</code> Add <code>st2_system_user</code> to the sudoers (recommended for most <code>st2</code> features to work). <code>st2_ssh_key_file</code> <code>/home/{{st2_system_user}}/.ssh/{{st2_system_user}}_rsa</code> Path to <code>st2_system_user</code> SSH private key. It will be autogenerated by default. <code>st2_auth_enable</code> <code>yes</code> Enable StackStorm standalone authentication. <code>st2_auth_username</code> <code>testu</code> Username used by StackStorm standalone authentication. <code>st2_auth_password</code> <code>testp</code> Password used by StackStorm standalone authentication. <code>st2_save_credentials</code> <code>yes</code> Save credentials for local CLI in <code>/root/.st2/config</code> file. <code>st2_packs</code> <code>[ st2 ]</code> List of packs to install. This flag does not work with a <code>--python3</code> only pack. st2web <code>st2web_ssl_certificate</code> <code>null</code> String with custom SSL certificate (<code>.crt</code>). If not provided, self-signed certificate will be generated. <code>st2web_ssl_certificate_key</code> <code>null</code> String with custom SSL certificate secret key (<code>.key</code>). If not provided, self-signed certificate will be generated. <code>st2web_nginx_config</code> <code>null</code> String with a custom nginx configuration file (<code>st2.conf</code>). If not provided, the default st2.conf will be used. ewc <code>ewc_license</code> <code>null</code> EWC license key is required for installing EWC enteprise bits via this ansible role. <code>ewc_repo</code> <code>enterprise</code> EWC PackageCloud repository to install. <code>enterprise</code>, <code>enterprise-unstable</code>, <code>staging-enterprise</code>, <code>staging-enterprise-unstable</code> <code>ewc_version</code> <code>latest</code> EWC enterprise version to install. <code>present</code> to install available package, <code>latest</code> to get automatic updates, or pin it to numeric version like <code>2.2.0</code>. The version used here should match <code>st2_version</code>. <code>ewc_revision</code> <code>1</code> EWC enterprise revision to install. Used only with pinned <code>ewc_version</code>. <code>ewc_rbac</code> See <code>ewc_rbac</code> variable in role defaults EWC RBAC roles and assignments. This is a dictionary with two keys <code>roles</code> and <code>assignments</code>. <code>roles</code> and <code>assignments</code> are in turn both arrays. Each element in the array follows the exact YAML schema for roles and assignments defined in EWC documentation. <code>ewc_ldap</code> See <code>ewc_ldap</code> variable in role defaults Settings for EWC LDAP authentication backend. <code>ewc_ldap</code> is a dictionary and has one item <code>backend_kwargs</code>. <code>backend_kwargs</code> should be provided as exactly listed in EWC documentation for LDAP configuration. st2chatops <code>st2chatops_version</code> <code>latest</code> st2chatops version to install. <code>present</code> to install available package, <code>latest</code> to get automatic updates, or pin it to numeric version like <code>2.2.0</code>. <code>st2chatops_st2_api_key</code> st2 API key to be updated in st2chatops.env using \"st2 apikey create -k\" in a task <code>st2chatops_hubot_adapter</code> Hubot Adapter to be used for st2chatops. Default is <code>shell</code>, but should be changed to one of the <code>supported adapters</code>.[Required] <code>st2chatops_config</code> <code>{ }</code> Based on adapter in <code>st2chatops_hubot_adapter</code>, provide hash for the adapter settings, to update <code>st2chatops.env</code>. For example, for <code>Slack</code> hubot adapter: <code>st2chatops_config:</code> <code>HUBOT_SLACK_TOKEN: xoxb-CHANGE-ME-PLEASE</code> <code>st2chatops_version</code> <code>latest</code> st2chatops version to install. Use <code>latest</code> to get automatic updates or pin it to numeric version like <code>2.2.0</code>."},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#examples","title":"Examples","text":"<p>Install latest <code>stable</code> StackStorm with all its components on local machine: <pre><code>ansible-playbook stackstorm.yml -i 'localhost,' --connection=local\n</code></pre></p> <p>Note that keeping <code>latest</code> version is useful to update StackStorm by re-running playbook, since it will reinstall st2 if there is new version available. This is default behavior. If you don't want updates - consider pinning version-revision numbers.</p> <p>Install specific numeric version of st2 with pinned revision number as well: <pre><code>ansible-playbook stackstorm.yml --extra-vars='st2_version=2.2.0 st2_revision=8'\n</code></pre></p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#installing-behind-a-proxy","title":"Installing behind a proxy.","text":"<p>If you are installing from behind a proxy, you can use environment variables <code>http_proxy</code>, <code>https_proxy</code>, and <code>no_proxy</code> in the playbook. For the st2smoketests, you will need to disable proxy for localhost.</p> <pre><code>  environment:\nhttp_proxy: http://proxy.example.net:3128\nhttps_proxy: http://proxy.example.net:3128\nno_proxy: 127.0.0.1,localhost\n</code></pre>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#developing","title":"Developing","text":"<p>There are a few requirements when developing on <code>ansible-st2</code>.</p> <p>These are the platforms we must support (must pass end-to-end testing): - Ubuntu Xenial - Ubuntu Bionic - CentOS7 - CentOS8 - RHEL7 (via AWS) - RHEL8 (via AWS)</p> <p>Must also support Ansible Idempotence (Eg. Ansible-playbook re-run should end with the following results: <code>changed=0.*failed=0</code>)</p> <p>For development purposes there is Vagrantfile available. The following command will setup ubuntu18 box (<code>ubuntu/bionic64</code>) by default: <pre><code>vagrant up\n</code></pre></p> <p>Other distros: <pre><code>vagrant up ubuntu16\nvagrant up centos7\nvagrant up centos8\n</code></pre></p>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#other-installers","title":"Other Installers","text":"<p>You might be interested in other methods to deploy StackStorm engine: * Configuration Management   * Chef Cookbook   * Puppet Module</p> <ul> <li>Manual Instructions</li> <li>Ubuntu 16.04</li> <li>Ubuntu 18.04</li> <li>RHEL8/CentOS8</li> <li>RHEL7/CentOS7</li> </ul>"},{"location":"examples/bitops%2Bterraform%2Bansible%2Bstackstorm-blog/st2-bitops-test/ansible/#help","title":"Help","text":"<p>If you're in stuck, our community always ready to help, feel free to: * Ask questions in our public Slack channel * Report bug, provide feature request or just give us a \u272e star</p> <p>Your contribution is more than welcome!</p>"},{"location":"examples/bitops%2Bterraform%2Bansible-blog/","title":"Bitops Operations Repo for WebServer deployment","text":"<p>This repo is based on the HOWTO blog post Combine Terraform and Ansible to Provision and Configure a Web Server</p> <p>This deployment can be run with: <pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=\"us-east-2\" \\\n-e TF_STATE_BUCKET=\"ansible_terraform_blog\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops%2Bterraform-blog/","title":"Bitops Operations Repo","text":"<p>Welcome to Bitops! This serves as a starting point for deploying your application to the cloud.</p> <p>This repo can be run as is with <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=\"us-east-2\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops-deploy-heyemoji/","title":"Bitops Operations Repo for HeyEmoji app deployment","text":"<p>This repo is based on the HOWTO blog post How to Deploy a HeyEmoji Slack App to AWS using Terraform.</p> <p>This deployment can be run with: <pre><code>docker run \\\n-e BITOPS_ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=\"$AWS_ACCESS_KEY_ID\" \\\n-e AWS_SECRET_ACCESS_KEY=\"$AWS_SECRET_ACCESS_KEY\" \\\n-e AWS_DEFAULT_REGION=\"us-east-2\" \\\n-e TF_STATE_BUCKET=\"heyemoji-blog\" \\\n-e HEYEMOJI_SLACK_API_TOKEN=\"$HEYEMOJI_SLACK_API_TOKEN\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre> Make sure to populate the secret ENV variables like <code>$AWS_ACCESS_KEY_ID</code>, <code>$AWS_SECRET_ACCESS_KEY</code>, and <code>$HEYEMOJI_SLACK_API_TOKEN</code>.</p> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/bitops2-terraform-blog/","title":"Bitops Operations Repo","text":"<p>This example shows a minimal Terraform configuration that creates an EKS cluster in <code>test</code> environment with a shared <code>_default</code> dir as an introduction to BitOps v2.0.</p> <p>See our blog post Getting started with BitOps v2.0 - Terraform on how this is used</p> <pre><code>docker run --rm \\\n-e BITOPS_ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n-e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e AWS_DEFAULT_REGION=\"us-east-2\" \\\n-v $(pwd):/opt/bitops_deployment \\\n--pull always \\\nbitovi/bitops:2.0.0\n</code></pre> <p>For more information, check out official BitOps docs https://bitovi.github.io/bitops/</p>"},{"location":"examples/helm-default-environment/","title":"Index","text":"<p>To run this example, open a terminal in this directory and run <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=skip \\\n-e AWS_SECRET_ACCESS_KEY=skip \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p>"},{"location":"examples/terraform-and-ansible/","title":"Index","text":"<p>This example shows how terraform could be used to provision infrastructure and then passed on to ansible for configuration.</p> <p>To run this example, open a terminal in this directory and run <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=skip \\\n-e AWS_SECRET_ACCESS_KEY=skip \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>In the logs you will see:</p> <p>Creation of <code>hosts.yaml</code> <pre><code>Terraform will perform the following actions:\n\n  # local_file.ansible_inventory will be created\n  + resource \"local_file\" \"ansible_inventory\" {\n      + content              = &lt;&lt;~EOT\n            my-servers:\n              hosts:\n                localhost  \n              vars:\n                ansible_connection: local\n        EOT\n      + directory_permission = \"0777\"\n      + file_permission      = \"0777\"\n      + filename             = \"/tmp/tmp.hxYnhz1NCU/test/terraform/hosts.yaml\"\n      + id                   = (known after apply)\n    }\n\n  # null_resource.test_resource will be created\n  + resource \"null_resource\" \"test_resource\" {\n      + id = (known after apply)\n    }\n\nPlan: 2 to add, 0 to change, 0 to destroy.\n</code></pre></p> <p>A terraform post hook showing the contents of <code>hosts.yaml</code> <pre><code>+ cat hosts.yaml\nmy-servers:\n  hosts:\n    localhost  \n  vars:\n    ansible_connection: local\n</code></pre></p> <p>The ansible playbook running using <code>hosts.yaml</code> as its input <pre><code>ok: [localhost]\n\nTASK [debug] *******************************************************************\nok: [localhost] =&gt; {\n    \"msg\": \"ansible debug\"\n}\n\nPLAY RECAP *********************************************************************\nlocalhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n</code></pre></p>"},{"location":"examples/terraform-default-environment/","title":"Index","text":"<p>To run this example, open a terminal in this directory and run <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=skip \\\n-e AWS_SECRET_ACCESS_KEY=skip \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre> This should prodcue the terraform logs: <pre><code>null_resource.test_resource: Creating...\nnull_resource.test_resource: Provisioning with 'local-exec'...\nnull_resource.test_resource (local-exec): Executing: [\"/bin/sh\" \"-c\" \"echo I am a test terraform resource\"]\nnull_resource.test_resource (local-exec): I am a test terraform resource\nnull_resource.test_resource: Creation complete after 0s [id=1053230725969363428]\n</code></pre></p>"},{"location":"examples/terraform-lifecycle-hooks/","title":"Index","text":"<p>To run this example, open a terminal in this directory and run <pre><code>docker run \\\n-e ENVIRONMENT=\"test\" \\\n-e AWS_ACCESS_KEY_ID=skip \\\n-e AWS_SECRET_ACCESS_KEY=skip \\\n-e AWS_DEFAULT_REGION=\"us-east-1\" \\\n-v $(pwd):/opt/bitops_deployment \\\nbitovi/bitops:latest\n</code></pre></p> <p>We should see logs showing the before and after scripts running <pre><code>+ /bin/bash -x /tmp/tmp.4jcNkVb3sN/test/terraform/bitops.before-deploy.d/my-before-script.sh\nI am a before terraform lifecycle script!\n+ set -x\n+ echo 'I am a before terraform lifecycle script!'\n...\nnull_resource.test_resource: Creating...\nnull_resource.test_resource: Provisioning with 'local-exec'...\nnull_resource.test_resource (local-exec): Executing: [\"/bin/sh\" \"-c\" \"echo I am a test terraform resource\"]\nnull_resource.test_resource (local-exec): I am a test terraform resource\nnull_resource.test_resource: Creation complete after 0s [id=8496749575343682584]\n...\n+ /bin/bash -x /tmp/tmp.4jcNkVb3sN/test/terraform/bitops.after-deploy.d/my-after-script.sh\n+ set -x\n+ echo 'I am a after terraform lifecycle script!'\nI am a after terraform lifecycle script!\n</code></pre></p>"},{"location":"tool-configuration/bitops.schema/","title":"Summary","text":""},{"location":"tool-configuration/bitops.schema/#schema","title":"Schema","text":"<pre><code>bitops:\nops_repo:\nsource: &lt;value&gt;\nfail_fast: &lt;value&gt;\nlogging:\nlevel: &lt;value&gt;\nplugins:\nplugin_seq:\n- &lt;value&gt;\n- &lt;value&gt;\ntools:\ncloudprovider:\n&lt;cloudprovider&gt;:\nsource: &lt;value&gt;\ntools:\n&lt;tool&gt;:\nsource: &lt;value&gt;\nsource_tag: &lt;value&gt;\nsource_branch: &lt;value&gt;\ninstall_script: &lt;value&gt;\ndeploy_script: &lt;value&gt;\n</code></pre>"},{"location":"tool-configuration/bitops.schema/#configuration-explanation","title":"Configuration explanation","text":"Property Values allowed Description Default Required bitops.ops_repo.source <code>local</code> or URL to Project code example: https://github.com/PhillypHenning/test-opsrepo.git Location of the Operations Repository bitops.failfast <code>True</code> or <code>False</code> Sets an internal flag which if true will exit the application if an exception occurs. bitops.logging.level <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>,  <code>CRITICAL</code> The logging level bitops.plugins.plugin_seq List of values using the same alias names given to the deployment tools. The sequence of execution for the plugins bitops.plugins.tools.cloudproviders Describes the cloud provider that will be installed and used to deploy bitops.plugins.tools.deployment Describes the deployment tools that will be installed and used to deploy"},{"location":"tool-configuration/configuration-ansible/","title":"Ansible","text":"<p>\u26a0\ufe0f For more information on this tool please checkout Ansible plugin repository.</p>"},{"location":"tool-configuration/configuration-ansible/#ansible","title":"Ansible","text":""},{"location":"tool-configuration/configuration-ansible/#example-bitopsconfigyaml-minimum-required","title":"Example <code>bitops.config.yaml</code>, minimum required:","text":"<pre><code>ansible:\ncli: {}\noptions: {}\n</code></pre>"},{"location":"tool-configuration/configuration-ansible/#example-complete-bitopsconfigyaml","title":"Example complete <code>bitops.config.yaml</code>:","text":"<pre><code>ansible:\ncli:\nmain-playbook: playbook.yaml\nextra-vars: \"@extra-vars.json\"\nflush-cache: true\nforce-handlers: true\nforks: 20\ninventory: beta\nskip-tags: ignore-this-tag\ntags: run-with-this-tag\ndryrun: false\noptions:\nverbosity: 0\nskip-deploy: false\n</code></pre>"},{"location":"tool-configuration/configuration-ansible/#cli-configuration","title":"CLI configuration","text":"<p>CLI configuration is used to pass in CLI parameters to the ansible-playbook command.</p> Parameter Environment Variable Type Required Default Description <code>main-playbook</code> <code>BITOPS_ANSIBLE_MAIN_PLAYBOOK</code> string yes <code>playbook.yaml</code> Specify which playbook to run ansible-playbook with <code>extra-vars</code> <code>BITOPS_ANSIBLE_EXTRA_VARS</code> string Add additional ansible playbook parameters directly or load via JSON/YAML file. <code>flush-cache</code> <code>BITOPS_ANSIBLE_FLUSH_CACHE</code> boolean Clear the fact cache for every host in inventory. <code>force-handlers</code> <code>BITOPS_ANSIBLE_FORCE_HANDLERS</code> boolean Clear the fact cache for every host in inventory. <code>forks</code> <code>BITOPS_ANSIBLE_FORKS</code> integer Specify number of parallel processes to use. <code>inventory</code> <code>BITOPS_ANSIBLE_INVENTORY</code> string Specify inventory host path or comma separated host list. <code>skip-tags</code> <code>BITOPS_ANSIBLE_SKIP_TAGS</code> string Only run plays and tasks whose tags do not match these values. <code>tags</code> <code>BITOPS_ANSIBLE_TAGS</code> string Only run plays and tasks tagged with these values. <code>dryrun</code> <code>BITOPS_ANSIBLE_DRYRUN</code> boolean Don't make any changes; instead, try to predict some of the changes that may occur."},{"location":"tool-configuration/configuration-ansible/#options-configuration","title":"Options Configuration","text":"<p>Options configurations are used to export variables without using the CLI generation or for any advanced logic that is not supported by the Ansible CLI.</p> Parameter Environment Variable Type Required Default Description <code>skip-deploy</code> <code>ANSIBLE_SKIP_DEPLOY</code> boolean If set to \"true\", regardless of the stack-action, deployment actions will be skipped. <code>verbosity</code> <code>BITOPS_ANSIBLE_VERBOSITY</code> integer Equivalent to adding <code>-verbose</code> or repeating <code>-v</code> flags. Will override <code>[default]</code> <code>verbosity=</code> setting in ansible.cfg. Acceptable values <code>0\\|1\\|2\\|3\\|4</code>."},{"location":"tool-configuration/configuration-cloudformation/","title":"Cloudformation","text":"<p>\u26a0\ufe0f Note from the developers: We are currently in the process of moving our documentation and so the below documentation is only partially correct. For more information on this tool please checkout our plugin documentation.</p>"},{"location":"tool-configuration/configuration-cloudformation/#cloudformation","title":"Cloudformation","text":""},{"location":"tool-configuration/configuration-cloudformation/#example-bitopsconfigyaml","title":"Example bitops.config.yaml","text":"<pre><code>cloudformation:\ncli:\nvalidate-cfn: true\nstack-action: deploy\noptions:\ncfn-stack-name: bitops-edgelambda-test\ncapabilities: CAPABILITY_NAMED_IAM\ncfn-files:\ntemplate-file: template.yaml\nparameters:\nenabled: true\ntemplate-param-file: parameters.json\n</code></pre>"},{"location":"tool-configuration/configuration-cloudformation/#cli-configuration","title":"CLI Configuration","text":"Property Environmental Variable Description Default Required validate-cfn FN_TEMPLATE_VALIDATION Calls <code>aws cloudformation validate-template</code> <code>true</code> stack-action CFN_STACK_ACTION Controls what CloudFormation action to apply on the stack <code>deploy</code>"},{"location":"tool-configuration/configuration-cloudformation/#options-configuration","title":"Options Configuration","text":"Property Environmental Variable Description Default Required cfn-stack-name CFN_STACK_NAME Cloudformation stack name <code>null</code> capabilities CFN_CAPABILITY Allows you to use CloudFormation nested stacks. Both properties must be set in order to use nested stacks. <code>null</code> cfn-s3-bucket CFN_TEMPLATE_S3_BUCKET <code>null</code> cfn-s3-prefix CFN_S3_PREFIX <code>null</code> cfn-merge-parameters Cloudformation capabilities"},{"location":"tool-configuration/configuration-cloudformation/#cfn-files","title":"cfn-files","text":"<p>BitOps Property: <code>cfn-files</code></p> <p>Allows for param files to be used. Has the following child-properties</p> Property Environmental Variable Description Default Required cfn-files.template-file Template file to apply the params against cfn-files.parameters Additional parameters. cfn-files.parameters.enabled CFN_PARAMS_FLAG <code>true</code> cfn-files.parameters.template-param-file CFN_TEMPLATE_PARAMS_FILENAME <code>null</code> cfn-merge-parameters Allows for param files to be used. Has the following child-properties cfn-files.enabled CFN_MERGE_PARAMETER True if optional option should be used. <code>false</code> cfn-files.directory CFN_MERGE_DIRECTORY The directory within the ansible workspace that contains json files that will be merged. <code>parameters</code> <p>Although not captured in <code>bitops.config.yaml</code>, the following environment variables can be set to further customize the behavior</p> Environmental Variable Description CFN_SKIP_DEPLOY Will skill all CloudFormation executions. This supersedes all other configuration"},{"location":"tool-configuration/configuration-helm/","title":"Helm","text":"<p>\u26a0\ufe0f Note from the developers: We are currently in the process of moving our documentation and so the below documentation is only partially correct. For more information on this tool please checkout our plugin documentation.</p>"},{"location":"tool-configuration/configuration-helm/#helm","title":"Helm","text":""},{"location":"tool-configuration/configuration-helm/#example-bitopsconfigyaml","title":"Example bitops.config.yaml","text":"<pre><code>helm:\n  cli:\n    namespace: bitops\n    timeout: 60s\n    set:\n     - \"key1=value1\"\n     - \"key2=value2\"\n    debug: false\n    atomic: true\n    force: true\n    dry-run: true\n  options:\n    skip-deploy: false\n    release-name: bitops-release\n    uninstall-charts: \"chart1,chart2\"\n    kubeconfig:\n      path: ./path/to/kubeconfig\n      fetch:\n        enabled: true\n        cluster-name: my-cluster\n  plugins:\n</code></pre>"},{"location":"tool-configuration/configuration-helm/#cli-configuration","title":"CLI Configuration","text":"Property Environment Variable Description Default Required namespace NAMESPACE Namespace scope for this project <code>null</code> Yes timeout TIMEOUT Time to wait for any individual Kubernetes operation (like Jobs for hooks) <code>500s</code> set HELM_SET_FLAG List of \"key=value\" strings to pass in to <code>helm</code> via <code>--set</code> <code>{}</code> debug HELM_DEBUG Enable verbose helm output <code>null</code> atomic If set, the installation process deletes the installation on failure <code>null</code> force Sets helm's <code>--force</code> flag <code>null</code> dry-run Simulate an install <code>null</code>"},{"location":"tool-configuration/configuration-helm/#options-configuration","title":"Options Configuration","text":"Property Environment Variable Description Default Required skip-deploy HELM_SKIP_DEPLOY Will skip helm execution <code>null</code> release-name HELM_RELEASE_NAME Sets helm release name <code>null</code> uninstall HELM_UNINSTALL If true, this chart will be uninstalled instead of deployed/upgraded. If the environment variable <code>HELM_UNINSTALL</code> is passed into the container, all BitOps-managed charts for a given environment will be uninstalled. <code>null</code> kubeconfig configure cluster access. Has the following child-properties. Should provide one of <code>path</code> or <code>fetch</code>. Defaults to <code>fetch</code> <code>fetch</code> kubeconfig.path KUBE_CONFIG_PATH Relative file path to .kubeconfig file <code>null</code> kubeconfig.fetch Fetch kubeconfig using cloud provider auth kubeconfig.fetch.enabled FETCH_KUBECONFIG enables/disables kubeconfig.fetch <code>true</code> kubeconfig.fetch.cluster-name CLUSTER_NAME Cloud kubernetes cluster name for kubeconfig fetching. <code>null</code>"},{"location":"tool-configuration/configuration-helm/#plugin-configuration","title":"Plugin Configuration","text":"<p>This section of <code>bitops.config.yaml</code> is unique to helm and allows the customization of helm plugins</p>"},{"location":"tool-configuration/configuration-helm/#s3-plugin","title":"S3 Plugin","text":"<p>Configure helm s3 plugin with the following properties</p> Property Environment Variable Description Default Required s3.region HELM_PLUGIN_S3_REGION AWS region containing s3 bucket s3.bucket HELM_CHARTS_S3_BUCKET AWS s3 bucket name"},{"location":"tool-configuration/configuration-helm/#additional-environment-variable-configuration","title":"Additional Environment Variable Configuration","text":"<p>Although not captured in <code>bitops.config.yaml</code>, the following environment variables can be set to further customize behavior.</p> Environmental Variable Description HELM_SKIP_DEPLOY Will skip all helm executions. This supersedes all other configurations. HELM_UNINSTALL_CHARTS Comma-separated string. If any of the charts to be deployed match one of the chart names listed here, it will be uninstalled with <code>helm uninstall $HELM_RELEASE_NAME</code> instead of deployed/upgraded."},{"location":"tool-configuration/configuration-terraform/","title":"Terraform","text":"<p>\u26a0\ufe0f Note from the developers: We are currently in the process of moving our documentation and so the below documentation is only partially correct. For more information on this tool please checkout our plugin documentation.</p>"},{"location":"tool-configuration/configuration-terraform/#bitops-plugin-for-terraform","title":"Bitops Plugin for Terraform","text":""},{"location":"tool-configuration/configuration-terraform/#deployment","title":"Deployment","text":"<p><code>terraform</code> plugin uses <code>bitops.config.yaml</code> located in the operations repo when deploying resources using terraform scripts.</p>"},{"location":"tool-configuration/configuration-terraform/#example-bitopsconfigyaml-minimum-required","title":"Example <code>bitops.config.yaml</code>, minimum required","text":"<pre><code>terraform: {}\n</code></pre>"},{"location":"tool-configuration/configuration-terraform/#example-2-bitopsconfigyaml","title":"Example 2 <code>bitops.config.yaml</code>","text":"<pre><code>terraform:\n    cli:\n        var-file: my-vars.tfvars\n        targets: \n            - terraform.module.resource\n        backend-config:\n            - KEY1=foo\n            - KEY2=bar\n        stack-action: \"plan\"\n    options:\n        workspace: test\n</code></pre> <p>The <code>terraform</code> plugin will run <code>terraform init</code> and <code>terraform plan</code> on every execution.</p> <p>Run BitOps with the environmental variable <code>TERRAFORM_APPLY</code> set to <code>true</code> or set <code>stack-action</code> in the <code>bitops.config.yaml</code> file to apply to run <code>terraform apply</code>.</p>"},{"location":"tool-configuration/configuration-terraform/#cli-and-options-configuration-of-terraform-bitopsschemayaml","title":"CLI and options configuration of Terraform <code>bitops.schema.yaml</code>","text":""},{"location":"tool-configuration/configuration-terraform/#terraform-bitops-schema","title":"Terraform BitOps Schema","text":"<p>bitops.schema.yaml</p> Property Environment Variable CLI Argument Description Default Required var-file BITOPS_TF_VAR_FILE --var-file Terraform Varaible file <code>null</code> No targets BITOPS_TF_TARGETS --target  <code>null</code> No backend-config --KEY1=foo --KEY2=bar <code>null</code> No stack-action BITOPS_TERRAFORM_COMMAND Controls what terraform command to run. e.g. <code>apply</code>, <code>destroy</code>, etc. <code>plan</code> No"},{"location":"tool-configuration/configuration-terraform/#options-configuration","title":"Options Configuration","text":"Property Environment Variable Description Default Required skip-deploy TERRAFORM_SKIP_DEPLOY If set to true, regardless of the stack-action, deployment actions will be skipped. false No workspace BITOPS_TERRAFORM_WORKSPACE Will select a terraform workspace using <code>terraform workspace new $TERRAFORM_WORKSPACE ||terraform workspace select $TERRAFORM_WORKSPACE</code> prior to running other terraform commands. <code>null</code> No"},{"location":"tool-configuration/configuration-terraform/#additional-environment-variable-configuration","title":"Additional Environment Variable Configuration","text":"<p>Although not captured in <code>bitops.config.yaml</code>, the following environment variables can be set to further customize behavior.  Set the value of the environmental variable to <code>true</code> to enable its behavior.</p> Variable Description TERRAFORM_SKIP_DEPLOY Will skip all terraform executions. This supersedes all other configurations. TERRAFORM_APPLY Will force call <code>terraform apply</code>. TERRAFORM_DESTROY Will force call <code>terraform destroy</code>. INIT_UPGRADE Will add <code>--upgrade</code> flag to the init command."},{"location":"tool-configuration/configuration-terraform/#_1","title":"Terraform","text":""}]}